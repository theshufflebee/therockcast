---
title: "ECB Tests 6"
output:
  pdf_document: 
    toc: true
    fig_caption: yes
    latex_engine: lualatex
header-includes:
  - \usepackage{amsmath}
---
\newpage

```{r header}
#explain what his script does and why and how to run code in readme file
```


```{r library_setup, results=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
rm(list=ls())
require(tinytex) #LaTeX
require(ggplot2) #plots
require(AEC) #JP-Renne functions
require(AER) #NW formula
require(forecast) #time series forecasting
require(expm) #matrix exponents
require(here) #directory finder
require(dplyr) #data management
require(lubridate) #data dates management
require(zoo) #for lagging
require(jtools) #tables
require(huxtable) #tables
require(lmtest) #reg tests
require(vroom) #for loading data
require(data.table) #for data filtering
require(sysid) #for ARMA-X modeling
require(sandwich) #regression errors
require(stargazer) #nice reg tables
require(texreg) #arima tables
require(future.apply) #parallel computation (speed)
require(readxl) #for reading excel data
require(R.matlab) #for loading matlab data (shadowrates)
require(aTSA) #time series tests
require(eurostat) #eurostat data
require(fredr) #fredr data
require(mFilter) #HP filter
require(knitr) #tables
require(kableExtra) #tables extra
require(rdbnomics)
require(doParallel) #for speed
require(foreach) #for speedy loops
require(car) #for MZ hypothesis test
require(ggridges) #for fancy density plots

getwd()
setwd("...") 

#api for data
fredr_set_key("e0169694a62c1337f1969e3872605eca")

#dates
start_date <- "1999-01-01"
end_date <- Sys.Date()

#load helper functions
#source(here("auto_ARIMA_replic.R"))

set.seed(2025)
format <- "html"
#format <- "latex" 

```


# Data

## Main
```{r data_main, message=FALSE, warning=FALSE}

#REDO THE DATA LOADING USNING rdbnomics PACKAGE (combines all macro APIs)

# --- 1. ECB Deposit Facility Rate & Shadow Rate ---
ecb_rate_daily <- fredr(series_id = "ECBDFR", observation_start = as.Date(start_date))
ecb_rate_q <- ecb_rate_daily %>%
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarise(rate = last(value)) %>%
  mutate(date = as.Date(quarter))
# Wu-Xia Shadow Rate 
shadow_rate_daily = as.data.frame(readMat("data/shadowrate_ECB.mat")) 
colnames(shadow_rate_daily) <- c("DATE", "shadowrate")
shadow_rate_daily$DATE <- as.Date(paste0(shadow_rate_daily$DATE, "01"), format="%Y%m%d")
shadow_rate_daily$quarter <- as.yearqtr(as.Date(shadow_rate_daily$DATE))
shadow_rate_daily$month <- as.yearmon(as.Date(shadow_rate_daily$DATE))
quarterly_shadow = aggregate(shadowrate ~ quarter, data=shadow_rate_daily, FUN=mean, na.rm=T)
monthly_shadow = aggregate(shadowrate ~ month, data=shadow_rate_daily, FUN=mean, na.rm=T)

# --- 2. HICP Inflation (Euro Area) ---
inflation_data <- get_eurostat("prc_hicp_manr", filters = list(geo = "EA", coicop = "CP00"), type = "label")
inflation_q <- inflation_data %>%
  filter(time >= start_date) %>%
  select(date = time, inflation = values) %>%
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarise(inflation = mean(inflation, na.rm = TRUE)) %>%
  mutate(date = as.Date(quarter))

#inflation expectations
inflation_exp <- rdb(ids = "ECB/SPF/M.U2.HICP.POINT.P12M.Q.AVG")
#inflation_exp <- rdb(ids = "ECB/SPF/M.U2.HICP.POINT.P24M.Q.AVG")
inflation_exp_q <- inflation_exp %>%
  mutate(quarter = as.yearqtr(period)) %>%
  group_by(quarter) %>%
  summarise(exp_inflation = last(original_value)) %>%
  mutate(date = as.Date(quarter))

#P12M
inflation_q$exp_inflation = c(rep(NA,3),as.numeric(inflation_exp_q$exp_inflation),NA)
#P24M
#inflation_q$exp_inflation = c(rep(NA,7),as.numeric(inflation_exp_q$exp_inflation[1:101]))

# --- 3. Real GDP and Estimated Output Gap ---
# a) Real GDP for the Euro Area. The series ID is CLVMNACSCAB1GQE_A.
gdp_q <- fredr(
  series_id = "CLVMEURSCAB1GQEA19",
  observation_start = as.Date(start_date)) %>%
  mutate(quarter = as.yearqtr(date)) %>%
  select(quarter, real_gdp = value) %>%
  mutate(log_real_gdp = log(real_gdp)) 

# b) Estimate Potential GDP (the trend) using the HP Filter on the log of real GDP.
# The lambda value of 1600 is standard for quarterly data.
hp_gdp <- hpfilter(gdp_q$log_real_gdp, freq = 1600)
gdp_q$potential_gdp_log <- as.numeric(hp_gdp$trend)


# Combine all data into a single data frame
data <- ecb_rate_q %>%
  select(quarter, rate) %>%
  left_join(inflation_q, by = "quarter") %>%
  left_join(gdp_q, by = "quarter") %>%
  left_join(quarterly_shadow, by = "quarter") 

# Create model variables
data <- data %>%
  mutate(
    inflation_gap = inflation - 2.0,
    exp_inflation_gap = exp_inflation -2.0,
    output_gap = 100 * (log_real_gdp - potential_gdp_log),
    rate_lag = lag(rate, 1),
    shadowrate = case_when(
      quarter < "2012 Q3" | quarter >= "2022 Q3" ~ rate,
      TRUE ~ shadowrate),
    shadowrate_lag = lag(shadowrate, 1))

# Remove last row since no output
data = subset(data, quarter < "2025 Q3")

# Clean environment
rm(gdp_q, hp_gdp, ecb_rate_daily, ecb_rate_q, inflation_data, inflation_q,
   inflation_exp, inflation_exp_q, monthly_shadow, quarterly_shadow, shadow_rate_daily)

```

## Raw Data Plots
```{r data_plots, message=FALSE, warning=FALSE}

ggplot(data, aes(x = date, color = series)) +
  geom_line(aes(y = rate, color = "Rate"), linewidth = 1) +
  geom_line(aes(y = inflation, color = "Inflation"), linewidth = 1) +
  geom_line(aes(y = output_gap, color = "Output Gap"), linewidth = 1) +
  labs(title = "Raw Data Plots", 
       x = "", 
       y = "", 
       color = "Time Series") +
  theme_minimal()

```


## Data Properties
```{r data_prop, message=FALSE, warning=FALSE}

# Interest rate is I(1)
test1 = aTSA::adf.test(data$rate, output=F)
test1$type1

# Inflation is I(1)
test2 = aTSA::adf.test(data$inflation, output=F)
test2$type1

# Output gap is I(0), likely from the "gap" part
test3 = aTSA::adf.test(data$output_gap, output=F)
test3$type1

# Cleanup
rm(test1,test2,test3)

# Are interest rates and inflation co-integrated?
aTSA::coint.test(data$rate, data$inflation)

```



\newpage

# Taylor Rule Estimation

## Without Lag
$$
\begin{aligned}
  i_t &= \pi^* + \gamma(y_t-\bar{y_t}) + \beta(\pi_t-\pi^*) \\
      &= (1-\beta)\pi^* + \gamma(y_t-\bar{y_t}) + \beta \pi_t
\end{aligned}
$$

```{r Taylor Rule simple w/o lag}

TR <- lm(rate ~ inflation_gap + output_gap, data = data)
TRsr <- lm(shadowrate ~ inflation_gap + output_gap, data = data)

export_summs(TR, TRsr, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR"), digits = 4)

```

```{r Taylor Rule simple w/o lag but with inflatione expectations}

TR_e <- lm(rate ~ exp_inflation_gap + output_gap, data = data)
TRsr_e <- lm(shadowrate ~ exp_inflation_gap + output_gap, data = data)
TR_ie <- lm(rate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)
TRsr_ie <- lm(shadowrate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)

export_summs(TR_e, TRsr_e, TR_ie, TRsr_ie, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)

```


## With Lag (interest rate smoothing)
$$
\begin{aligned}
      &= \phi i_{t-1} + (1-\beta)\pi^* + \gamma(y_t-\bar{y_t}) + \beta \pi_t
\end{aligned}
$$

```{r Taylor Rule simple w/ lag}

lTR <- lm(rate ~ rate_lag + inflation_gap + output_gap, data = data)
lTRsr <- lm(shadowrate ~ shadowrate_lag + inflation_gap + output_gap, data = data)

export_summs(lTR, lTRsr, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR"), digits = 4)

```
```{r Taylor Rule simple w/ lag and inflation expectations}

lTR_e <- lm(rate ~ rate_lag + exp_inflation_gap + output_gap, data = data)
lTRsr_e <- lm(shadowrate ~ shadowrate_lag + exp_inflation_gap + output_gap, data = data)
lTR_ie <- lm(rate ~ rate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
lTRsr_ie <- lm(shadowrate ~ shadowrate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
export_summs(lTR_e, lTRsr_e, lTR_ie,lTRsr_ie, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)

```





\newpage

# Forecasting Model Evaluation

## Helpers
```{r helpers}

#-------------------------------------------------------------------
# Helper function for adding p-value significance stars
#-------------------------------------------------------------------

  format_p_values_with_stars <- function(p) {
    stars <- case_when(
      p < 0.01 ~ "***",
      p < 0.05 ~ "**",
      p < 0.10 ~ "*",
      TRUE     ~ "")
    paste0(format(round(p, 4), nsmall = 3), " ", stars)}

#-------------------------------------------------------------------
# HELPER FUNCTION FOR MINCER-ZARNOWITZ REPORTING
#-------------------------------------------------------------------
# This function runs the Mincer-Zarnowitz regression (Actuals ~ Forecasts)
# for each horizon h and tests the joint null hypothesis H0: (alpha, beta) = (0, 1).
#-------------------------------------------------------------------

generate_mincer_zarnowitz_report <- function(F_model, 
                                             Actual_values, 
                                             H, 
                                             model_caption, 
                                             format = "html") {
  # Pre-allocate storage for results
  mz_results <- data.frame(
    Horizon = 1:H,
    Alpha = numeric(H),
    Beta = numeric(H),
    P_Value_Joint_Test = numeric(H))
  
  for (h in 1:H) {
    # 1. Create a clean data frame for this horizon
    #    This pairs the forecasts and actual values and removes any NAs,
    #    ensuring they remain perfectly aligned.
    df_h <- data.frame(
      actuals = Actual_values[[h]],
      forecasts = F_model[[h]] ) %>%
      na.omit() 
    
    # Check if we have enough data to run the regression (at least 2 obs)
    if (nrow(df_h) > 2) {
      # 2. Run MZ regression
      mz_reg <- lm(actuals ~ forecasts, data = df_h)
      
      # 3. Get coefficients
      coeffs <- summary(mz_reg)$coefficients
      mz_results$Alpha[h] <- coeffs[1, 1] 
      mz_results$Beta[h]  <- coeffs[2, 1] 
      
      # Using NW errors as seen in class, with lag selection h-1
      v_matrix <-
        if (h == 1) {
          # h=1: No autocorrelation, use standard "White" (HC) errors
          sandwich::vcovHC(mz_reg, type = "HC3")
        } else {
          # h>1: Use Newey-West, manually setting lag = h-1
          sandwich::NeweyWest(mz_reg, lag = h - 1)}
      
      # 4. Test Joint Hypothesis H0: Alpha = 0 AND Beta = 1 and store pvalues
      test_joint <- linearHypothesis(mz_reg,
                       c("(Intercept) = 0", "forecasts = 1"), vcov. = v_matrix)
      mz_results$P_Value_Joint_Test[h] <- test_joint$"Pr(>F)"[2]

    } else {
      # Not enough data to run regression for this horizon
      mz_results$Alpha[h] <- NA_real_
      mz_results$Beta[h]  <- NA_real_
      mz_results$P_Value_Joint_Test[h] <- NA_real_ } }
  
  # Format the results for the table
  mz_results <- mz_results %>%
    mutate(Alpha = round(Alpha, 4),
           Beta = round(Beta, 4),
           P_Value_Joint_Test = format_p_values_with_stars(P_Value_Joint_Test))
    
  # Create the table
  table_output <- kable(
    mz_results,
    format = format,
    booktabs = TRUE,
    caption = model_caption,
    digits = 4,
    col.names = c("h", "Alpha", "Beta", "pv(Joint)"),
    escape = FALSE ) %>%
    kable_styling(
      latex_options = c("striped", "scale_down"),
      position = "center") %>%
    column_spec(1, bold = TRUE, border_right = TRUE) %>%
    column_spec(4, monospace = TRUE) %>%
    footnote(
      general = "pv(Joint) is the p-value for the joint hypothesis H_0: (Alpha, Beta) = (0, 1). A high p-value means we fail to reject the null hypothesis of an unbiased, efficient forecast.",
      symbol = c(
        "Signif. codes:  '***' 0.01,  '**' 0.05,  '*' 0.1"),
      general_title = "Note:",
      symbol_title = "",
      footnote_as_chunk = TRUE,
      threeparttable = TRUE)
  return(table_output) }



#-------------------------------------------------------------------
# HELPER FUNCTION FOR REPORTING DM tests
#-------------------------------------------------------------------

# This function creates the DM tests and kable output
generate_report_table <- function(FE_TR_model, FE_BM_model, H, model_caption, format = "html") { MSFE_TR = numeric(H)
  MSFE_BM = numeric(H)
  
  # Calculate MSFEs
  for (h in 1:H) {
    # Ensure errors are cleaned of NAs
    fe1 <- na.omit(FE_TR_model[[h]])
    fe2 <- na.omit(FE_BM_model[[h]])
    
    MSFE_TR[h] = mean((fe1)^2)
    MSFE_BM[h] = mean((fe2)^2)}
  
  # Run DM Tests
  DMpvalues = matrix(, nrow = H, ncol = 3)
  colnames(DMpvalues) <- c("DM_Two_Sided", "DM_Greater", "DM_Lesser")
  for (h in 1:H){
    # Note: dm.test needs the *full* (un-omitted) error vectors
    # to align them properly, hence using the original list inputs
    x1 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h)
    x2 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h, alternative = "greater")
    x3 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h, alternative = "less")
    DMpvalues[h, 1] = round(x1$p.value, digits = 4)
    DMpvalues[h, 2] = round(x2$p.value, digits = 4)
    DMpvalues[h, 3] = round(x3$p.value, digits = 4)}

  # Create final table data
  forecast_comparison <- data.frame(
    Horizon = 1:H,
    MSFE_TR = MSFE_TR,
    MSFE_BM = MSFE_BM) %>%
    mutate(Ratio_TR_vs_BM = MSFE_TR / MSFE_BM)
  
  forecast_comparison <- bind_cols(forecast_comparison, as.data.frame(DMpvalues))
  
  final_data_formatted <- forecast_comparison %>%
    mutate(across(starts_with("DM_"), format_p_values_with_stars))
  
  # Create the kable table
  table_output <- kable(
    final_data_formatted,
    format = format,
    booktabs = TRUE,
    caption = model_caption,
    digits = 4,
    col.names = c("h", "MSFE TR", "MSFE BM", "Ratio", "DM Two-Sided", "DM Greater", "DM Lesser"),
    escape = FALSE) %>%
    kable_styling(
      latex_options = c("striped", "scale_down"),
      position = "center") %>%
    column_spec(1, bold = TRUE, border_right = TRUE) %>%
    column_spec(5:7, monospace = TRUE) %>%
    footnote(
      general = "TR refers to the forecast made with an estimated Taylor Rule. BM refers to a benchmark of the interest rate using an ARIMA model. Ratio < 1 indicates that the TR model has lower MSFE.",
      symbol = c(
        "'DM Greater' tests if the TR model is significantly more accurate than the BM model.",
        "'DM Lesser' tests if the TR model is significantly less accurate than the BM model."),
      general_title = "Note:",
      symbol_title = "DM Test Alternative Hypotheses (H_A):",
      footnote_as_chunk = TRUE,
      threeparttable = TRUE)

  return(table_output)}

```


## Estimation
```{r forecast-model-main, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

#parameters
R = 54-28-8 #note: start of ZLB at R=54
R = 54+28
P = nrow(data) - R #but will effectively be: P = T-h-R
H = 10 #number of different horizons

#note: we are doing a recursive estimation scheme for out-of-sample tests
#note: we are doing direct forecasts (check with Viktor)

#-------------------------------------------------------------------
# 1. DEFINE THE FOUR TAYLOR RULE (TR) MODEL FORMULAS
#-------------------------------------------------------------------

# TR based on current inflation
formula_1 <- rate ~ inflation_gap + output_gap
formula_2 <- shadowrate ~ inflation_gap + output_gap
formula_3 <- rate ~ rate_lag + inflation_gap + output_gap
formula_4 <- shadowrate ~ shadowrate_lag + inflation_gap + output_gap

# TR based on current inflation expectations of inflation in 12 months
#formula_1 <- rate ~ exp_inflation_gap + output_gap
#formula_2 <- shadowrate ~ exp_inflation_gap + output_gap
#formula_3 <- rate ~ rate_lag + exp_inflation_gap + output_gap
#formula_4 <- shadowrate ~ shadowrate_lag + exp_inflation_gap + output_gap

#-------------------------------------------------------------------
# 2. PRE-ALLOCATE STORAGE FOR ALL RESULTS
#-------------------------------------------------------------------

# We need 4 lists for the TR models, 1 list for the shared benchmark
init_storage_list <- function(H, P) {
  storage <- vector("list", length = H)
  for (h in 1:H) {
    storage[[h]] <- rep(NA_real_, P)}
  return(storage)}

# Storage for realised values 
Actuals <- init_storage_list(H, P)

# Storage for Forecasts 
F_TR_1 <- init_storage_list(H, P) # Model 1: shadowrate, no lag
F_TR_2 <- init_storage_list(H, P) # Model 2: rate, no lag
F_TR_3 <- init_storage_list(H, P) # Model 3: shadowrate, with lag
F_TR_4 <- init_storage_list(H, P) # Model 4: rate, with lag
F_BM   <- init_storage_list(H, P) # Benchmark: ARIMA

# Storage for Forecast Errors 
FE_TR_1 <- init_storage_list(H, P) # Model 1: shadowrate, no lag
FE_TR_2 <- init_storage_list(H, P) # Model 2: rate, no lag
FE_TR_3 <- init_storage_list(H, P) # Model 3: shadowrate, with lag
FE_TR_4 <- init_storage_list(H, P) # Model 4: rate, with lag
FE_BM   <- init_storage_list(H, P) # Benchmark: ARIMA


#-------------------------------------------------------------------
# 3. SETUP & RUN THE PARALLEL BACKTESTING LOOP
#-------------------------------------------------------------------
num_cores <- detectCores() - 1 
cl <- makeCluster(num_cores)
registerDoParallel(cl)

# .export sends read-only objects to each core
# .packages loads libraries on each core
worker_results <- foreach(
  p = P:1, 
  .packages = c("forecast", "stats", "dplyr"),
  .export = c("data", "H", "formula_1", "formula_2", "formula_3", "formula_4")
) %dopar% {
  
  # 1. Define splits
  training <- data[1:(nrow(data) - p), ]
  testing <- data[(nrow(data) - (p - 1)):nrow(data), ]
  
  # --- 2. Fit common models only once ---
  inflation_arma <- auto.arima(training$inflation_gap, max.p=4, max.q=4, max.d=1)
  #exp_inflation_arma <- auto.arima(training$exp_inflation_gap, max.p=4, max.q=4, max.d=1)
  outputgap_arma <- auto.arima(training$output_gap, max.p=4, max.q=4, max.d=1)
  interest_arma <- auto.arima(training$rate, max.p=4, max.q=4, max.d=1) # Benchmark
  
  # --- 3. Get common forecasts only once (all H horizons) ---
  inflation_forecasts <- forecast::forecast(inflation_arma, h = H)$mean
  #exp_inflation_forecasts <- forecast::forecast(exp_inflation_arma, h = H)$mean
  outputgap_forecasts <- forecast::forecast(outputgap_arma, h = H)$mean
  BMpredicted_rates <- forecast::forecast(interest_arma, h = H)$mean
  
  # --- 4. Fit the 4 TR models ---
  TR_model_1 <- lm(formula_1, data = training)
  TR_model_2 <- lm(formula_2, data = training)
  TR_model_3 <- lm(formula_3, data = training)
  TR_model_4 <- lm(formula_4, data = training)
  
  # --- 5. Build forecast input data & get forecasts for non-lagged models ---
  # These are direct forecasts
  new_data_base <- data.frame(
    inflation_gap = inflation_forecasts,
    #exp_inflation_gap = exp_inflation_forecasts,
    output_gap = outputgap_forecasts)
    
  TR_preds_1 <- pmax(predict(TR_model_1, new_data_base), min(data$rate))
  TR_preds_2 <- pmax(predict(TR_model_2, new_data_base), min(data$rate))
  BM_preds   <- pmax(BMpredicted_rates, min(data$rate)) # Benchmark
  
  # --- 6. Get forecasts for lagged models via iteration ---
  # We must loop 1 step at a time, feeding forecasts back in.   
  
  # a) Pre-allocate storage for H forecasts
  TR_preds_3 <- numeric(H)
  TR_preds_4 <- numeric(H)
  
  # b) Get the last known lag from the training set (lag for h=1 forecast)
  current_rate_lag  <- last(training$rate)
  current_shadowrate_lag <- last(training$shadowrate)

  # Loop for iterative forecasting 
  for (h in 1:H) {
    # --- Prepare dataset for predictions ---
    new_data_3_h <- data.frame(
      inflation_gap = inflation_forecasts[h],
      #exp_inflation_gap = exp_inflation_forecasts[h],
      output_gap = outputgap_forecasts[h],
      rate_lag = current_rate_lag)
    new_data_4_h <- data.frame(
      inflation_gap = inflation_forecasts[h],
      #exp_inflation_gap = exp_inflation_forecasts[h],
      output_gap = outputgap_forecasts[h],
      shadowrate_lag = current_shadowrate_lag )
    
    # Get the forecast values
    pred_3_h <- pmax(predict(TR_model_3, new_data_3_h), min(data$rate))
    TR_preds_3[h] <- pred_3_h
    pred_4_h <- pmax(predict(TR_model_4, new_data_4_h), min(data$rate))
    TR_preds_4[h] <- pred_4_h
    
    # Update lag for h+1 
    current_shadowrate_lag <- pred_4_h
    current_rate_lag <- pred_3_h }

  # --- 7. Get actual values in evaluation sample  ---
  actual_rates <- testing$rate[1:H]
  
  # --- 8. Return all FORECASTS and ACTUALS from the worker ---
  list(f_tr1 = TR_preds_1,
       f_tr2 = TR_preds_2,
       f_tr3 = TR_preds_3,
       f_tr4 = TR_preds_4,
       f_bm  = BM_preds,
       actuals = actual_rates) }
    
# --- Stop the Cluster ---
stopCluster(cl)
rm(cl)

#-------------------------------------------------------------------
# 4. UNPACK PARALLEL RESULTS INTO STORAGE LISTS
#-------------------------------------------------------------------

# 'worker_results' is a list of P lists. We need to re-organize it.
for (i in 1:P) {
  # i=1 corresponds to p=P, i=2 to p=P-1, ... i=P to p=1
  # This 'storage_index' matches the loop order
  storage_index <- i 
  p_results <- worker_results[[i]]
  
  for (h in 1:H) {
    # Get the raw values for this h
    actual_val <- p_results$actuals[h]
    f_tr1_val  <- p_results$f_tr1[h]
    f_tr2_val  <- p_results$f_tr2[h]
    f_tr3_val  <- p_results$f_tr3[h]
    f_tr4_val  <- p_results$f_tr4[h]
    f_bm_val   <- p_results$f_bm[h]
    
    # Store Actuals (for MZ)
    Actuals[[h]][storage_index] <- actual_val
    
    # Store Forecasts (for MZ)
    F_TR_1[[h]][storage_index] <- f_tr1_val
    F_TR_2[[h]][storage_index] <- f_tr2_val
    F_TR_3[[h]][storage_index] <- f_tr3_val
    F_TR_4[[h]][storage_index] <- f_tr4_val
    F_BM[[h]][storage_index]   <- f_bm_val
    
    # Calculate and Store Errors (for MSFE/DM)
    FE_TR_1[[h]][storage_index] <- f_tr1_val - actual_val
    FE_TR_2[[h]][storage_index] <- f_tr2_val - actual_val
    FE_TR_3[[h]][storage_index] <- f_tr3_val - actual_val
    FE_TR_4[[h]][storage_index] <- f_tr4_val - actual_val
    FE_BM[[h]][storage_index]   <- f_bm_val  - actual_val } }

#-------------------------------------------------------------------
# 5. RENDER RESULTS MORE INTUITIVE FOR FURTHER ANALYSIS
#-------------------------------------------------------------------

# Convert the forecast lists (F_TR_x) into single dataframes
forecast_to_df <- function(forecast_list, period) {
  # Convert each element to numeric (benchmark is ts object, which is bad)
  numeric_list <- lapply(forecast_list, function(x) as.numeric(x)) #just make each list inside numeric
  df <- as.data.frame(numeric_list)
  # Add period and horizon
  df$period <- period #first list is all horizon 1 forecasts, gives this to all observations
  df$horizon <- 1:nrow(df) #counts rows and gives each the horizon corresponding to it
  df}

# Apply to all forecasting models
df_all <- do.call(rbind, lapply(seq_along(worker_results), function(i) {
  forecast_to_df(worker_results[[i]], period = i) }))
df_all[] <- lapply(df_all, function(x) as.numeric(x))

```

## Spaghetti Plots
```{r Spaghetti Plot, message=FALSE, warning=FALSE}

# Select the model to plot
model <- "f_tr3"

# period = date the forecast was made
# date_of_forecast = the future date we are predicting
df_all$date_of_forecast <- df_all$period + df_all$horizon # is this correct choice?

# Spaghetti plot with color per period
ggplot(df_all, aes(x = date_of_forecast, y = .data[[model]], group = period, color = factor(period))) +
  geom_line(alpha = 0.7) +    # forecast lines
  geom_point(shape = 2, alpha = 0.7) +
  
  # Actuals as black baseline
  geom_line(aes(y = actuals), color = "black", size = 1) +
  geom_point(aes(y = actuals), color = "black", shape = 4, alpha = 0.5) +
  
  labs(
    title = paste("Forecast of", model, "vs Actual Rate"),
    x = "Period",
    y = "Interest Rate",
    color = "Forecast Origin") +
  theme_minimal()

```

## Plots of FE
```{r Plot of Forecast Errors, warning=FALSE, message=FALSE}

df_all_3 <- df_all

# Compute forecast error
df_all_3$forecast_error <- df_all_3[[model]] - df_all_3$actuals

#compute date_of_forecast for x-axis
df_all_3$date_of_forecast <- df_all_3$period + df_all_3$horizon

ggplot(df_all_3, aes(x = date_of_forecast, group = period)) +
  # Forecast error lines
  geom_line(aes(y = forecast_error), color = "blue", alpha = 0.5) +
  geom_point(aes(y = forecast_error), color = "blue", alpha = 0.5, shape = 4) +
  
  # Actuals line
  geom_line(aes(y = actuals), color = "black", size = 1) +
  geom_point(aes(y = actuals), color = "black", shape = 4, alpha = 0.5) +
  
  labs(
    title = paste("Forecast Errors for", model),
    x = "Below Zero = forecast was too low ; Above Zero = forecast too high",
    y = "Interest Rate and Forecast Error (deviation from interest rate)"
  ) +
  theme_minimal()

```
## Density of FE
```{r Density of Forecast Errors}

# Version 1: Non-Adjusted Scales
plot_facet <- ggplot(df_all_3 %>% filter(horizon <= H), aes(x = forecast_error)) +
  geom_density(fill = "#3498db", color = "#2980b9", alpha = 0.6) +
  facet_wrap(~horizon, ncol = 4, labeller = label_both, scales = "free") +
  labs(
    title = "Density of Forecast Errors by Horizon (Non-Adjusted Scale)",
    subtitle = "Comparing distribution shapes across 12 horizons",
    x = "Forecast Error",
    y = "Density"
  ) +
  theme_minimal() +
  theme(
    strip.background = element_rect(fill = "#ecf0f1", color = NA), # Nice gray boxes for labels
    strip.text = element_text(face = "bold"))
print(plot_facet)

# Version 2: Adjusted scales
plot_facet <- ggplot(df_all_3 %>% filter(horizon <= H), aes(x = forecast_error)) +
  geom_density(fill = "#3498db", color = "#2980b9", alpha = 0.6) +
  facet_wrap(~horizon, ncol = 4, labeller = label_both) +
  labs(title = "Density of Forecast Errors by Horizon (Adjusted Scale)",
    subtitle = "Comparing distribution shapes across 12 horizons",
    x = "Forecast Error",
    y = "Density") +
  theme_minimal() +
  theme(strip.background = element_rect(fill = "#ecf0f1", color = NA), 
    strip.text = element_text(face = "bold"))
print(plot_facet)

# Version 3: "Ridges"
plot_ridge <- ggplot(df_all_3 %>% filter(horizon <= H),
                       aes(x = forecast_error, y = as.factor(horizon), fill = stat(x))) +
    geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
    scale_fill_viridis_c(name = "Error", option = "C") +
    labs(title = "Evolution of Forecast Error Densities",
      subtitle = "Ridge plot showing widening variance over longer horizons",
      x = "Forecast Error",
      y = "Forecast Horizon") +
    theme_minimal()

print(plot_ridge)
 
```

## Variance of FE
```{r Variance of Forecast Errors}

# This gives us the mean forecast error for the h step ahead forecast
var_by_horizon <- df_all_3 %>%
  group_by(horizon) %>%
  summarize(
    mean_fe = mean(forecast_error, na.rm=T),
    var_fe = sd(forecast_error, na.rm=T)^2, n = n() )

ggplot(var_by_horizon, aes(x = horizon, y = var_fe)) +
  geom_line(color = "#2c3e50", size = 1) +
  geom_point(color = "#e74c3c", size = 3, alpha = 0.8) +
  theme_minimal(base_size = 14) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Variance of FE by Horizon",
    x = "Forecast Horizon",
    y = "Variance of FE",
    caption = "Data source: df_all_3") +
  theme(plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(color = "gray50"),
        panel.grid.minor.x = element_blank() )

```

## Absolute Performance: Efficiency \& Bias
```{r forecast-model-efficiency, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Call MZ-test helper function 4 times.

# MZ Report 1: Actual Rate, No Lag
mz_report_1 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_1,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Actual Rate, No Lag",
  format = format)

# MZ Report 2: Shadow Rate, No Lag
mz_report_2 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_2,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Shadow Rate, No Lag",
  format = format)

# MZ Report 3: Actual Rate, with Lag
mz_report_3 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_3,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Actual Rate, with Lag",
  format = format)

# MZ Report 4: Shadow Rate, with Lag
mz_report_4 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_4,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Shadow Rate, with Lag",
  format = format)

# MZ Report 5: Benchmark
mz_report_BM <- generate_mincer_zarnowitz_report(
  F_model = F_BM,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Benchmark ARIMA",
  format = format)

list(
  mz_report_1, 
  mz_report_2, 
  mz_report_3, 
  mz_report_4, 
  mz_report_BM)

```


## Relative Performance (against benchmark)
```{r forecast-model-perf, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Call DM-test helper function 4 times.

# Report 1: Actual Rate, No Lag
report_1 <- generate_report_table(
  FE_TR_model = FE_TR_1,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, No Lag",
  format = format)

# Report 2: Shadow Rate, No Lag
report_2 <- generate_report_table(
  FE_TR_model = FE_TR_2,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Shadow Rate, No Lag",
  format = format)

# Report 3: Actual Rate, with Lag
report_3 <- generate_report_table(
  FE_TR_model = FE_TR_3,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, with Lag",
  format = format)

# Report 4: Shadow Rate, with Lag
report_4 <- generate_report_table(
  FE_TR_model = FE_TR_4,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Shadow Rate, with Lag",
  format = format)

list(report_1, report_2, report_3, report_4)

```

\newpage


# Actual Forecast Model

## Helpers
```{r our_helper, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

#-------------------------------------------------------------------
# Helper function for displaying our final forecast results
#-------------------------------------------------------------------

display_forecasts <- function(forecast_list, 
                              caption = "Interest Rate Forecasts", 
                              format = "html") {
  
  # Determine the number of horizons and corresponding quarters
  H <- length(forecast_list$TR_Forecast)
  
  forecast_quarters <- seq(from = last(data$quarter) + 0.25, 
                           by = 0.25, 
                           length.out = H)
  
  horizon_quarter_label <- paste0(1:H, ": ", as.character(forecast_quarters))
  
  # Create a data frame for display
  forecast_df <- data.frame(
    Horizon_Quarter = horizon_quarter_label,
    Taylor_Rule_Forecast = round(forecast_list$TR_Forecast,4),
    Benchmark_ARIMA_Forecast = round(forecast_list$BM_Forecast,4))
  
  # Create the table
  table_output <- kable(
    forecast_df,
    format = format,
    digits = 4,
    col.names = c("Horizon: Quarter", "Taylor Rule Forecast", "Benchmark Forecast"),
    caption = caption,
    booktabs = TRUE) %>%
  kable_styling(
    latex_options = "striped",
    position = "center") %>%
  column_spec(1, bold = TRUE, border_right = TRUE)
    return(table_output) }

```

## Forecasting
```{r forecast, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Formula 4 seems to work best
our_predict <- function(data,formula,H){

  # --- 1. Fit inputs and benchmark models  ---
   inflation_arma <- auto.arima(data$inflation_gap, max.p=4, max.q=4, max.d=1)
   #exp_inflation_arma <- auto.arima(data$exp_inflation_gap, max.p=4, max.q=4, max.d=1)
   outputgap_arma <- auto.arima(data$output_gap, max.p=4, max.q=4, max.d=1)
   interest_arma <- auto.arima(data$rate, max.p=4, max.q=4, max.d=1) # Benchmark
  
  # --- 2. Get forecasts of inputs (all H horizons) ---
   inflation_forecasts <- forecast::forecast(inflation_arma, h = H)$mean
   #exp_inflation_forecasts <- forecast::forecast(exp_inflation_arma, h = H)$mean
   outputgap_forecasts <- forecast::forecast(outputgap_arma, h = H)$mean
   BMpredicted_rates <- forecast::forecast(interest_arma, h = H)$mean
  
  # --- 3. Fit TR model
   TR_model <- lm(formula, data = data)
    
  # --- 4. Build forecast input data frame (iteratively for lags) ---
   
   # Allocate storage for full horizon
   TR_preds <- numeric(H)
   
   # Get last known lags (starting point for lagged models)
   current_shadowrate_lag <- last(data$shadowrate)
   current_rate_lag <- last(data$rate)
   
  for (h in 1:H) {
     new_data_h <- data.frame(
        inflation_gap = inflation_forecasts[h],
        #exp_inflation_gap = exp_inflation_forecasts[h],
        output_gap = outputgap_forecasts[h],
        shadowrate_lag = current_shadowrate_lag,
        rate_lag = current_rate_lag)
     
     # Get forecasted values
     pred_h <- pmax(predict(TR_model, new_data_h), min(data$rate))
     TR_preds[h] <- pred_h
     
     # Update the lag for h+1
     current_rate_lag <- pred_h }
     
   # --- 5. Compute forecast for BM ---
    BM_preds   <- pmax(BMpredicted_rates, min(data$rate)) # Benchmark 
    
  return(list(TR_Forecast = TR_preds, BM_Forecast = BM_preds))}

 
final_forecasts <- our_predict(data = data, formula = formula_3, H = H)
 
display_forecasts(final_forecasts, 
                  caption = "",
                  format = format)
 
```




















