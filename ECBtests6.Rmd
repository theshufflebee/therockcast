---
title: "ECB Tests 6"
output:
  pdf_document: 
    toc: true
    fig_caption: yes
    latex_engine: lualatex
header-includes:
  - \usepackage{amsmath}
---
\newpage

# Communication

## Instructions:

### Data
* Load data for: Deposit rate, Shadow rate, HICP inflation rate, and real GDP
* Make all data quarterly
* Use HP filter to estimate potential real GDP
* Combine variables in one dataset
* Modify dataset by computing inflation gap, output gap, and replacing shadowrate values 

### Taylor Rule 
* Preemptively estimate Taylor Rule to check coefficients
* Do so with and without including a lag

### Forecasting
* Define number of different horizons to estimate (H)
* Define evaluation sample (P, R)
* For each horizon
* For each step in evaluation sample
* Select the data for training based on evaluation sample dates
* Select the data for testing based on evaluation sample dates
* Estimate Taylor Rule
* Fit an ARIMA model for inflation gap and output gap
* Forecast inflation gap and output gap for current horizon based on ARIMA
* Put these forecasts in new dataset and call "forecast datsaset"
* Use this new dataset to predict values of the interest rate based on the fitted taylor rule model
* Remove predicted values below ZLB
* Compute forecast errors by taking predicted rate minus the actual rate from the testing sample 
* Fit a benchmark ARIMA model for interest rate
* Forecast interest rate for current horizon based on ARIMA
* Remove predicted values below ZLB
* Compute forecast errors by taking forecasted rate minus the actual rate from the testing sample
* Compute mean of these forecast errors for the current horizon
* For each horizon compute run a DM test taking the MSFE of the TR model against the MSFE of the benchmark model
* Create a table which compares the MSFE and pvalues for TR against benchmark


## Step after instructions

Predict interest rate Using forecast_dataset on TR model

(last line in inst)
For horizon, compute DM TEST
Use MFSE of TR against benchmark 

## Pseudo Code
basically just python code


Tips
-write functions for everything
-one function one task for modularity and also add the return line in R for explicit
-go multi file overleaf style
-use tidyverse more
-X13 arima-seats to correct for seasonality with {seasonal} package
-avoid setwd, use here() and make full code a one shot run multifile to make viktor happy
-NOT ALLOWED TO USE {forecast} PACKAGE ask maybe if we are allowed since we do TR
-for EVERY package function EXPLICITY call package::function (BRUH ask viktor to make sure)
-GDP download seasonally adjusted

\newpage

```{r header}
#explain what his script does and why and how to run code in readme file
```


```{r library_setup, results=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
rm(list=ls())
require(tinytex) #LaTeX
require(ggplot2) #plots
require(AEC) #JP-Renne functions
require(AER) #NW formula
require(forecast) #time series forecasting
require(expm) #matrix exponents
require(here) #directory finder
require(dplyr) #data management
require(lubridate) #data dates management
require(zoo) #for lagging
require(jtools) #tables
require(huxtable) #tables
require(lmtest) #reg tests
require(vroom) #for loading data
require(data.table) #for data filtering
require(sysid) #for ARMA-X modeling
require(sandwich) #regression errors
require(stargazer) #nice reg tables
require(texreg) #arima tables
require(future.apply) #parallel computation (speed)
require(readxl) #for reading excel data
require(R.matlab) #for loading matlab data (shadowrates)
require(aTSA) #time series tests
require(eurostat) #eurostat data
require(fredr) #fredr data
require(mFilter) #HP filter
require(knitr) #tables
require(kableExtra) #tables extra
require(rdbnomics)
require(doParallel) #for speed
require(foreach) #for speedy loops
require(car) #for MZ hypothesis test

getwd()
setwd("...") 

#api for data
fredr_set_key("e0169694a62c1337f1969e3872605eca")

#dates
start_date <- "1999-01-01"
end_date <- Sys.Date()

#load helper functions
#source(here("helperfunctions/data_loaders.R"))

set.seed(2025)
format <- "html"
#format <- "latex" 

```


# Data

## Main
```{r data, message=FALSE, warning=FALSE}

#REDO THE DATA LOADING USNING rdbnomics PACKAGE (combines all macro APIs)

# --- 1. ECB Deposit Facility Rate & Shadow Rate ---
ecb_rate_daily <- fredr(series_id = "ECBDFR", observation_start = as.Date(start_date))
ecb_rate_q <- ecb_rate_daily %>%
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarise(rate = last(value)) %>%
  mutate(date = as.Date(quarter))
# Wu-Xia Shadow Rate 
shadow_rate_daily = as.data.frame(readMat("data/shadowrate_ECB.mat")) 
colnames(shadow_rate_daily) <- c("DATE", "shadowrate")
shadow_rate_daily$DATE <- as.Date(paste0(shadow_rate_daily$DATE, "01"), format="%Y%m%d")
shadow_rate_daily$quarter <- as.yearqtr(as.Date(shadow_rate_daily$DATE))
shadow_rate_daily$month <- as.yearmon(as.Date(shadow_rate_daily$DATE))
quarterly_shadow = aggregate(shadowrate ~ quarter, data=shadow_rate_daily, FUN=mean, na.rm=T)
monthly_shadow = aggregate(shadowrate ~ month, data=shadow_rate_daily, FUN=mean, na.rm=T)

# --- 2. HICP Inflation (Euro Area) ---
inflation_data <- get_eurostat("prc_hicp_manr", filters = list(geo = "EA", coicop = "CP00"), type = "label")
inflation_q <- inflation_data %>%
  filter(time >= start_date) %>%
  select(date = time, inflation = values) %>%
  mutate(quarter = as.yearqtr(date)) %>%
  group_by(quarter) %>%
  summarise(inflation = mean(inflation, na.rm = TRUE)) %>%
  mutate(date = as.Date(quarter))

#inflation expectations
inflation_exp <- rdb(ids = "ECB/SPF/M.U2.HICP.POINT.P12M.Q.AVG")
#inflation_exp <- rdb(ids = "ECB/SPF/M.U2.HICP.POINT.P24M.Q.AVG")
inflation_exp_q <- inflation_exp %>%
  mutate(quarter = as.yearqtr(period)) %>%
  group_by(quarter) %>%
  summarise(exp_inflation = last(original_value)) %>%
  mutate(date = as.Date(quarter))

#P12M
inflation_q$exp_inflation = c(rep(NA,3),as.numeric(inflation_exp_q$exp_inflation),NA)
#P24M
#inflation_q$exp_inflation = c(rep(NA,7),as.numeric(inflation_exp_q$exp_inflation[1:101]))

# --- 3. Real GDP and Estimated Output Gap ---
# a) Real GDP for the Euro Area. The series ID is CLVMNACSCAB1GQE_A.
gdp_q <- fredr(
  series_id = "CLVMEURSCAB1GQEA19",
  observation_start = as.Date(start_date)) %>%
  mutate(quarter = as.yearqtr(date)) %>%
  select(quarter, real_gdp = value) %>%
  mutate(log_real_gdp = log(real_gdp)) 

# b) Estimate Potential GDP (the trend) using the HP Filter on the log of real GDP.
# The lambda value of 1600 is standard for quarterly data.
hp_gdp <- hpfilter(gdp_q$log_real_gdp, freq = 1600)
gdp_q$potential_gdp_log <- as.numeric(hp_gdp$trend)


# Combine all data into a single data frame
data <- ecb_rate_q %>%
  select(quarter, rate) %>%
  left_join(inflation_q, by = "quarter") %>%
  left_join(gdp_q, by = "quarter") %>%
  left_join(quarterly_shadow, by = "quarter") 

# Create model variables
data <- data %>%
  mutate(
    inflation_gap = inflation - 2.0,
    exp_inflation_gap = exp_inflation -2.0,
    output_gap = 100 * (log_real_gdp - potential_gdp_log),
    rate_lag = lag(rate, 1),
    shadowrate = case_when(
      quarter < "2012 Q3" | quarter >= "2022 Q3" ~ rate,
      TRUE ~ shadowrate),
    shadowrate_lag = lag(shadowrate, 1))

# Remove last row since no output
data = subset(data, quarter < "2025 Q3")

# Clean environment
rm(gdp_q, hp_gdp, ecb_rate_daily, ecb_rate_q, inflation_data, inflation_q,
   inflation_exp, inflation_exp_q, monthly_shadow, quarterly_shadow, shadow_rate_daily)

```
\newpage

# Taylor Rule Estimation

## Without Lag
$$
\begin{aligned}
  i_t &= \pi^* + \gamma(y_t-\bar{y_t}) + \beta(\pi_t-\pi^*) \\
      &= (1-\beta)\pi^* + \gamma(y_t-\bar{y_t}) + \beta \pi_t
\end{aligned}
$$

```{r Taylor Rule simple w/o lag}

TR <- lm(rate ~ inflation_gap + output_gap, data = data)
TRsr <- lm(shadowrate ~ inflation_gap + output_gap, data = data)

export_summs(TR, TRsr, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR"), digits = 4)

```

```{r Taylor Rule simple w/o lag but with inflatione expectations}

TR_e <- lm(rate ~ exp_inflation_gap + output_gap, data = data)
TRsr_e <- lm(shadowrate ~ exp_inflation_gap + output_gap, data = data)
TR_ie <- lm(rate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)
TRsr_ie <- lm(shadowrate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)

export_summs(TR_e, TRsr_e, TR_ie, TRsr_ie, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)

```


## With Lag (interest rate smoothing)
$$
\begin{aligned}
      &= \phi i_{t-1} + (1-\beta)\pi^* + \gamma(y_t-\bar{y_t}) + \beta \pi_t
\end{aligned}
$$

```{r Taylor Rule simple w/ lag}

lTR <- lm(rate ~ rate_lag + inflation_gap + output_gap, data = data)
lTRsr <- lm(shadowrate ~ shadowrate_lag + inflation_gap + output_gap, data = data)

export_summs(lTR, lTRsr, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR"), digits = 4)

```
```{r Taylor Rule simple w/ lag and inflation expectations}

lTR_e <- lm(rate ~ rate_lag + exp_inflation_gap + output_gap, data = data)
lTRsr_e <- lm(shadowrate ~ shadowrate_lag + exp_inflation_gap + output_gap, data = data)
lTR_ie <- lm(rate ~ rate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
lTRsr_ie <- lm(shadowrate ~ shadowrate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
export_summs(lTR_e, lTRsr_e, lTR_ie,lTRsr_ie, vcov = sandwich::NeweyWest, 
          model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)

```





\newpage

# Forecasting Model

## Helpers
```{r helpers}

# Helper function for adding p-value significance stars

  format_p_values_with_stars <- function(p) {
    stars <- case_when(
      p < 0.01 ~ "***",
      p < 0.05 ~ "**",
      p < 0.10 ~ "*",
      TRUE     ~ "")
    paste0(format(round(p, 4), nsmall = 3), " ", stars)}



#-------------------------------------------------------------------
# HELPER FUNCTION FOR MINCER-ZARNOWITZ REPORTING
#-------------------------------------------------------------------
# This function runs the Mincer-Zarnowitz regression (Actuals ~ Forecasts)
# for each horizon h and tests the joint null hypothesis H0: (alpha, beta) = (0, 1).
#-------------------------------------------------------------------

generate_mincer_zarnowitz_report <- function(F_model, 
                                             Actual_values, 
                                             H, 
                                             model_caption, 
                                             format = "html") {
  # Pre-allocate storage for results
  mz_results <- data.frame(
    Horizon = 1:H,
    Alpha = numeric(H),
    Beta = numeric(H),
    P_Value_Joint_Test = numeric(H))
  
  for (h in 1:H) {
    # 1. Create a clean data frame for this horizon
    #    This pairs the forecasts and actual values and removes any NAs,
    #    ensuring they remain perfectly aligned.
    df_h <- data.frame(
      actuals = Actual_values[[h]],
      forecasts = F_model[[h]] ) %>%
      na.omit() 
    
    # Check if we have enough data to run the regression (at least 2 obs)
    if (nrow(df_h) > 2) {
      # 2. Run MZ regression
      mz_reg <- lm(actuals ~ forecasts, data = df_h)
      
      # 3. Get coefficients
      coeffs <- summary(mz_reg)$coefficients
      mz_results$Alpha[h] <- coeffs[1, 1] 
      mz_results$Beta[h]  <- coeffs[2, 1] 
      
      # Using NW errors as seen in class, with lag selection h-1
      v_matrix <-
        if (h == 1) {
          # h=1: No autocorrelation, use standard "White" (HC) errors
          sandwich::vcovHC(mz_reg, type = "HC3")
        } else {
          # h>1: Use Newey-West, manually setting lag = h-1
          sandwich::NeweyWest(mz_reg, lag = h - 1)}
      
      # 4. Test Joint Hypothesis H0: Alpha = 0 AND Beta = 1 and store pvalues
      test_joint <- linearHypothesis(mz_reg,
                       c("(Intercept) = 0", "forecasts = 1"), vcov. = v_matrix)
      mz_results$P_Value_Joint_Test[h] <- test_joint$"Pr(>F)"[2]

    } else {
      # Not enough data to run regression for this horizon
      mz_results$Alpha[h] <- NA_real_
      mz_results$Beta[h]  <- NA_real_
      mz_results$P_Value_Joint_Test[h] <- NA_real_ } }
  
  # Format the results for the table
  mz_results <- mz_results %>%
    mutate(Alpha = round(Alpha, 4),
           Beta = round(Beta, 4),
           P_Value_Joint_Test = format_p_values_with_stars(P_Value_Joint_Test))
    
  # Create the table
  table_output <- kable(
    mz_results,
    format = format,
    booktabs = TRUE,
    caption = model_caption,
    digits = 4,
    col.names = c("h", "Alpha", "Beta", "pv(Joint)"),
    escape = FALSE ) %>%
    kable_styling(
      latex_options = c("striped", "scale_down"),
      position = "center") %>%
    column_spec(1, bold = TRUE, border_right = TRUE) %>%
    column_spec(4, monospace = TRUE) %>%
    footnote(
      general = "pv(Joint) is the p-value for the joint hypothesis H_0: (Alpha, Beta) = (0, 1). A high p-value means we fail to reject the null hypothesis of an unbiased, efficient forecast.",
      symbol = c(
        "Signif. codes:  '***' 0.01,  '**' 0.05,  '*' 0.1"),
      general_title = "Note:",
      symbol_title = "",
      footnote_as_chunk = TRUE,
      threeparttable = TRUE)
  return(table_output) }



#-------------------------------------------------------------------
# HELPER FUNCTION FOR REPORTING DM tests
#-------------------------------------------------------------------

# This function creates the DM tests and kable output
generate_report_table <- function(FE_TR_model, FE_BM_model, H, model_caption, format = "html") { MSFE_TR = numeric(H)
  MSFE_BM = numeric(H)
  
  # Calculate MSFEs
  for (h in 1:H) {
    # Ensure errors are cleaned of NAs
    fe1 <- na.omit(FE_TR_model[[h]])
    fe2 <- na.omit(FE_BM_model[[h]])
    
    MSFE_TR[h] = mean((fe1)^2)
    MSFE_BM[h] = mean((fe2)^2)}
  
  # Run DM Tests
  DMpvalues = matrix(, nrow = H, ncol = 3)
  colnames(DMpvalues) <- c("DM_Two_Sided", "DM_Greater", "DM_Lesser")
  for (h in 1:H){
    # Note: dm.test needs the *full* (un-omitted) error vectors
    # to align them properly, hence using the original list inputs
    x1 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h)
    x2 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h, alternative = "greater")
    x3 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h, alternative = "less")
    DMpvalues[h, 1] = round(x1$p.value, digits = 4)
    DMpvalues[h, 2] = round(x2$p.value, digits = 4)
    DMpvalues[h, 3] = round(x3$p.value, digits = 4)}

  # Create final table data
  forecast_comparison <- data.frame(
    Horizon = 1:H,
    MSFE_TR = MSFE_TR,
    MSFE_BM = MSFE_BM) %>%
    mutate(Ratio_TR_vs_BM = MSFE_TR / MSFE_BM)
  
  forecast_comparison <- bind_cols(forecast_comparison, as.data.frame(DMpvalues))
  
  final_data_formatted <- forecast_comparison %>%
    mutate(across(starts_with("DM_"), format_p_values_with_stars))
  
  # Create the kable table
  table_output <- kable(
    final_data_formatted,
    format = format,
    booktabs = TRUE,
    caption = model_caption,
    digits = 4,
    col.names = c("h", "MSFE TR", "MSFE BM", "Ratio", "DM Two-Sided", "DM Greater", "DM Lesser"),
    escape = FALSE) %>%
    kable_styling(
      latex_options = c("striped", "scale_down"),
      position = "center") %>%
    column_spec(1, bold = TRUE, border_right = TRUE) %>%
    column_spec(5:7, monospace = TRUE) %>%
    footnote(
      general = "TR refers to the forecast made with an estimated Taylor Rule. BM refers to a benchmark of the interest rate using an ARIMA model. Ratio < 1 indicates that the TR model has lower MSFE.",
      symbol = c(
        "'DM Greater' tests if the TR model is significantly more accurate than the BM model.",
        "'DM Lesser' tests if the TR model is significantly less accurate than the BM model."),
      general_title = "Note:",
      symbol_title = "DM Test Alternative Hypotheses (H_A):",
      footnote_as_chunk = TRUE,
      threeparttable = TRUE)

  return(table_output)}

```


## Estimation
```{r forecast-model-main, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

#parameters
R = 54-28-8 #note: start of ZLB at R=54
R = 54+28
P = nrow(data) - R #but will effectively be: P = T-h-R
H = 12 #number of different horizons

#note: we are doing a recursive estimation scheme for out-of-sample tests
#note: we are doing direct forecasts (check with Viktor)

#-------------------------------------------------------------------
# 1. DEFINE THE FOUR TAYLOR RULE (TR) MODEL FORMULAS
#-------------------------------------------------------------------

# TR based on current inflation
formula_1 <- shadowrate ~ inflation_gap + output_gap
formula_2 <- rate ~ inflation_gap + output_gap
formula_3 <- shadowrate ~ shadowrate_lag + inflation_gap + output_gap
formula_4 <- rate ~ rate_lag + inflation_gap + output_gap

# TR based on current inflation expectations of inflation in 12 months
#formula_1 <- shadowrate ~ exp_inflation_gap + output_gap
#formula_2 <- rate ~ exp_inflation_gap + output_gap
#formula_3 <- shadowrate ~ shadowrate_lag + exp_inflation_gap + output_gap
#formula_4 <- rate ~ rate_lag + exp_inflation_gap + output_gap

#-------------------------------------------------------------------
# 2. PRE-ALLOCATE STORAGE FOR ALL RESULTS
#-------------------------------------------------------------------

# We need 4 lists for the TR models, 1 list for the shared benchmark
init_storage_list <- function(H, P) {
  storage <- vector("list", length = H)
  for (h in 1:H) {
    storage[[h]] <- rep(NA_real_, P)}
  return(storage)}

# Storage for realised values 
Actuals <- init_storage_list(H, P)

# Storage for Forecasts 
F_TR_1 <- init_storage_list(H, P) # Model 1: shadowrate, no lag
F_TR_2 <- init_storage_list(H, P) # Model 2: rate, no lag
F_TR_3 <- init_storage_list(H, P) # Model 3: shadowrate, with lag
F_TR_4 <- init_storage_list(H, P) # Model 4: rate, with lag
F_BM   <- init_storage_list(H, P) # Benchmark: ARIMA

# Storage for Forecast Errors 
FE_TR_1 <- init_storage_list(H, P) # Model 1: shadowrate, no lag
FE_TR_2 <- init_storage_list(H, P) # Model 2: rate, no lag
FE_TR_3 <- init_storage_list(H, P) # Model 3: shadowrate, with lag
FE_TR_4 <- init_storage_list(H, P) # Model 4: rate, with lag
FE_BM   <- init_storage_list(H, P) # Benchmark: ARIMA


#-------------------------------------------------------------------
# 3. SETUP & RUN THE PARALLEL BACKTESTING LOOP
#-------------------------------------------------------------------
num_cores <- detectCores() - 1 
cl <- makeCluster(num_cores)
registerDoParallel(cl)

# .export sends read-only objects to each core
# .packages loads libraries on each core
worker_results <- foreach(
  p = P:1, 
  .packages = c("forecast", "stats", "dplyr"),
  .export = c("data", "H", "formula_1", "formula_2", "formula_3", "formula_4")
) %dopar% {
  
  # 1. Define splits
  training <- data[1:(nrow(data) - p), ]
  testing <- data[(nrow(data) - (p - 1)):nrow(data), ]
  
  # --- 2. Fit common models only once ---
  inflation_arma <- auto.arima(training$inflation_gap, max.p=4, max.q=4, max.d=1)
  #exp_inflation_arma <- auto.arima(training$exp_inflation_gap, max.p=4, max.q=4, max.d=1)
  outputgap_arma <- auto.arima(training$output_gap, max.p=4, max.q=4, max.d=1)
  interest_arma <- auto.arima(training$rate, max.p=4, max.q=4, max.d=1) # Benchmark
  
  # --- 3. Get common forecasts only once (all H horizons) ---
  inflation_forecasts <- forecast::forecast(inflation_arma, h = H)$mean
  #exp_inflation_forecasts <- forecast::forecast(exp_inflation_arma, h = H)$mean
  outputgap_forecasts <- forecast::forecast(outputgap_arma, h = H)$mean
  BMpredicted_rates <- forecast::forecast(interest_arma, h = H)$mean
  
  # --- 4. Fit the 4 SPECIFIC TR models ---
  TR_model_1 <- lm(formula_1, data = training)
  TR_model_2 <- lm(formula_2, data = training)
  TR_model_3 <- lm(formula_3, data = training)
  TR_model_4 <- lm(formula_4, data = training)
  
  # --- 5. Build forecast input data frames ---
  # Base inputs (for Models 1 & 2)
  new_data_base <- data.frame(
    inflation_gap = inflation_forecasts,
    #exp_inflation_gap = exp_inflation_forecasts,
    output_gap = outputgap_forecasts)
  
  # Inputs for Model 3 (needs shadowrate_lag)
  new_data_3 <- data.frame(
    new_data_base,
    shadowrate_lag = testing$shadowrate_lag[1:H])
  
  # Inputs for Model 4 (needs rate_lag)
  new_data_4 <- data.frame(
    new_data_base,
    rate_lag = testing$rate_lag[1:H])

  # --- 6. Get H-step forecasts for all 5 models ---
  TR_preds_1 <- pmax(predict(TR_model_1, new_data_base), min(data$rate))
  TR_preds_2 <- pmax(predict(TR_model_2, new_data_base), min(data$rate))
  TR_preds_3 <- pmax(predict(TR_model_3, new_data_3), min(data$rate))
  TR_preds_4 <- pmax(predict(TR_model_4, new_data_4), min(data$rate))
  BM_preds   <- pmax(BMpredicted_rates, min(data$rate)) # Benchmark
  
  # --- 7. Get actual values in evaluation sample  ---
  actual_rates <- testing$rate[1:H]
  
  # --- 8. Return all FORECASTS and ACTUALS from the worker ---
  list(f_tr1 = TR_preds_1,
       f_tr2 = TR_preds_2,
       f_tr3 = TR_preds_3,
       f_tr4 = TR_preds_4,
       f_bm  = BM_preds,
       actuals = actual_rates) }
    
# --- Stop the Cluster ---
stopCluster(cl)
rm(cl)

#-------------------------------------------------------------------
# 4. UNPACK PARALLEL RESULTS INTO STORAGE LISTS
#-------------------------------------------------------------------

# 'worker_results' is a list of P lists. We need to re-organize it.
for (i in 1:P) {
  # i=1 corresponds to p=P, i=2 to p=P-1, ... i=P to p=1
  # This 'storage_index' matches the loop order
  storage_index <- i 
  p_results <- worker_results[[i]]
  
  for (h in 1:H) {
    # Get the raw values for this h
    actual_val <- p_results$actuals[h]
    f_tr1_val  <- p_results$f_tr1[h]
    f_tr2_val  <- p_results$f_tr2[h]
    f_tr3_val  <- p_results$f_tr3[h]
    f_tr4_val  <- p_results$f_tr4[h]
    f_bm_val   <- p_results$f_bm[h]
    
    # Store Actuals (for MZ)
    Actuals[[h]][storage_index] <- actual_val
    
    # Store Forecasts (for MZ)
    F_TR_1[[h]][storage_index] <- f_tr1_val
    F_TR_2[[h]][storage_index] <- f_tr2_val
    F_TR_3[[h]][storage_index] <- f_tr3_val
    F_TR_4[[h]][storage_index] <- f_tr4_val
    F_BM[[h]][storage_index]   <- f_bm_val
    
    # Calculate and Store Errors (for MSFE/DM)
    FE_TR_1[[h]][storage_index] <- f_tr1_val - actual_val
    FE_TR_2[[h]][storage_index] <- f_tr2_val - actual_val
    FE_TR_3[[h]][storage_index] <- f_tr3_val - actual_val
    FE_TR_4[[h]][storage_index] <- f_tr4_val - actual_val
    FE_BM[[h]][storage_index]   <- f_bm_val  - actual_val } }

```


## Efficiency
```{r forecast-model-efficiency, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Call MZ-test helper function 4 times.

# MZ Report 1: Shadowrate, No Lag
mz_report_1 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_1,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: ShadowRate, No Lag",
  format = format)

# MZ Report 2: Actual Rate, No Lag
mz_report_2 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_2,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Actual Rate, No Lag",
  format = format)

# MZ Report 3: Shadowrate, with Lag
mz_report_3 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_3,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: ShadowRate, with Lag",
  format = format)

# MZ Report 4: Actual Rate, with Lag
mz_report_4 <- generate_mincer_zarnowitz_report(
  F_model = F_TR_4,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Actual Rate, with Lag",
  format = format)

# MZ Report 5: Benchmark
mz_report_BM <- generate_mincer_zarnowitz_report(
  F_model = F_BM,
  Actual_values = Actuals,
  H = H,
  model_caption = "Mincer-Zarnowitz Test: Benchmark ARIMA",
  format = format)

list(
  mz_report_1, 
  mz_report_2, 
  mz_report_3, 
  mz_report_4, 
  mz_report_BM)

```


## Performance (against benchmark)
```{r forecast-model-perf, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Call DM-test helper function 4 times.

# Report 1: Shadowrate, No Lag
report_1 <- generate_report_table(
  FE_TR_model = FE_TR_1,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on ShadowRate, No Lag",
  format = format)

# Report 2: Actual Rate, No Lag
report_2 <- generate_report_table(
  FE_TR_model = FE_TR_2,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, No Lag",
  format = format)

# Report 3: Shadowrate, with Lag
report_3 <- generate_report_table(
  FE_TR_model = FE_TR_3,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on ShadowRate, with Lag",
  format = format)

# Report 4: Actual Rate, with Lag
report_4 <- generate_report_table(
  FE_TR_model = FE_TR_4,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, with Lag",
  format = format)

list(report_1, report_2, report_3, report_4)

```




# Our Forecast

```{r forecast, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}}

# Formula 4 seems to work best
our_predict <- function(data,formula){

  # --- 1. Fit inputs and benchmark models  ---
   inflation_arma <- auto.arima(data$inflation_gap, max.p=4, max.q=4, max.d=1)
   #exp_inflation_arma <- auto.arima(data$exp_inflation_gap, max.p=4, max.q=4, max.d=1)
   outputgap_arma <- auto.arima(data$output_gap, max.p=4, max.q=4, max.d=1)
   interest_arma <- auto.arima(data$rate, max.p=4, max.q=4, max.d=1) # Benchmark
  
  # --- 2. Get forecasts of inputs (all H horizons) ---
   inflation_forecasts <- forecast::forecast(inflation_arma, h = H)$mean
   #exp_inflation_forecasts <- forecast::forecast(exp_inflation_arma, h = H)$mean
   outputgap_forecasts <- forecast::forecast(outputgap_arma, h = H)$mean
   BMpredicted_rates <- forecast::forecast(interest_arma, h = H)$mean
  
  # --- 3. Fit TR model
   TR_model <- lm(formula_4, data = data)
    
  # --- 4. Build forecast input data frame ---
   new_data_base <- data.frame(
      inflation_gap = inflation_forecasts,
      #exp_inflation_gap = exp_inflation_forecasts,
      output_gap = outputgap_forecasts,
      rate_lag = data$rate_lag[1:H],
      shadowrate_lag = data$shadowrate_lag[1:H])
  
  # --- 5. Compute forecast ---
   TR_preds <- pmax(predict(TR_model, new_data_base), min(data$rate))
   BM_preds   <- pmax(BMpredicted_rates, min(data$rate)) # Benchmark 
  return(TR_preds,BM_preds)
   }
 
 our_predict(data=data,formula=formula_4)
 
```








