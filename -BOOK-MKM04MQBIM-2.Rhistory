position = "center") %>%
column_spec(1, bold = TRUE, border_right = TRUE) %>%
column_spec(5:7, monospace = TRUE) %>%
footnote(
general = "TR refers to the forecast made with an estimated Taylor Rule. BM refers to a benchmark of the interest rate using an ARIMA model. Ratio < 1 indicates that the TR model has lower MSFE.",
symbol = c(
"'DM Greater' tests if the TR model is significantly more accurate than the BM model.",
"'DM Lesser' tests if the TR model is significantly less accurate than the BM model."),
general_title = "Note:",
symbol_title = "DM Test Alternative Hypotheses (H_A):",
footnote_as_chunk = TRUE,
threeparttable = TRUE)
return(table_output)
}
#-------------------------------------------------------------------
# 3. PRE-ALLOCATE STORAGE FOR ALL RESULTS
#-------------------------------------------------------------------
# We need 4 lists for the TR models, 1 list for the shared benchmark
init_storage_list <- function(H, P) {
storage <- vector("list", length = H)
for (h in 1:H) {
storage[[h]] <- rep(NA_real_, P)}
return(storage)}
FE_TR_1 <- init_storage_list(H, P) # Model 1: shadowrate, no lag
FE_TR_2 <- init_storage_list(H, P) # Model 2: rate, no lag
FE_TR_3 <- init_storage_list(H, P) # Model 3: shadowrate, with lag
FE_TR_4 <- init_storage_list(H, P) # Model 4: rate, with lag
FE_BM   <- init_storage_list(H, P) # Benchmark: ARIMA
#-------------------------------------------------------------------
# 4. SETUP & RUN THE PARALLEL BACKTESTING LOOP
#-------------------------------------------------------------------
num_cores <- detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# .export sends read-only objects to each core
# .packages loads libraries on each core
worker_results <- foreach(
p = P:1,
.packages = c("forecast", "stats", "dplyr"),
.export = c("data", "H", "formula_1", "formula_2", "formula_3", "formula_4")
) %dopar% {
# 1. Define splits
training <- data[1:(nrow(data) - p), ]
testing <- data[(nrow(data) - (p - 1)):nrow(data), ]
# --- 2. Fit common models only once ---
inflation_arma <- auto.arima(training$inflation_gap, max.p=4, max.q=4, max.d=1)
#exp_inflation_arma <- auto.arima(training$exp_inflation_gap, max.p=4, max.q=4, max.d=1)
outputgap_arma <- auto.arima(training$output_gap, max.p=4, max.q=4, max.d=1)
interest_arma <- auto.arima(training$rate, max.p=4, max.q=4, max.d=1) # Benchmark
# --- 3. Get common forecasts only once (all H horizons) ---
inflation_forecasts <- forecast::forecast(inflation_arma, h = H)$mean
#exp_inflation_forecasts <- forecast::forecast(exp_inflation_arma, h = H)$mean
outputgap_forecasts <- forecast::forecast(outputgap_arma, h = H)$mean
BMpredicted_rates <- forecast::forecast(interest_arma, h = H)$mean
# --- 4. Fit the 4 SPECIFIC TR models ---
TR_model_1 <- lm(formula_1, data = training)
TR_model_2 <- lm(formula_2, data = training)
TR_model_3 <- lm(formula_3, data = training)
TR_model_4 <- lm(formula_4, data = training)
# --- 5. Build forecast input data frames ---
# Base inputs (for Models 1 & 2)
new_data_base <- data.frame(
inflation_gap = inflation_forecasts,
#exp_inflation_gap = exp_inflation_forecasts,
output_gap = outputgap_forecasts)
# Inputs for Model 3 (needs shadowrate_lag)
new_data_3 <- data.frame(
new_data_base,
shadowrate_lag = testing$shadowrate_lag[1:H])
# Inputs for Model 4 (needs rate_lag)
new_data_4 <- data.frame(
new_data_base,
rate_lag = testing$rate_lag[1:H])
# --- 6. Get H-step forecasts for all 5 models ---
TR_preds_1 <- pmax(predict(TR_model_1, new_data_base), min(data$rate))
TR_preds_2 <- pmax(predict(TR_model_2, new_data_base), min(data$rate))
TR_preds_3 <- pmax(predict(TR_model_3, new_data_3), min(data$rate))
TR_preds_4 <- pmax(predict(TR_model_4, new_data_4), min(data$rate))
BM_preds   <- pmax(BMpredicted_rates, min(data$rate)) # Benchmark
# --- 7. Compute errors against actuals ---
actual_rates <- testing$rate[1:H]
errors_TR_1 <- TR_preds_1 - actual_rates
errors_TR_2 <- TR_preds_2 - actual_rates
errors_TR_3 <- TR_preds_3 - actual_rates
errors_TR_4 <- TR_preds_4 - actual_rates
errors_BM   <- BM_preds   - actual_rates
# --- 8. Return all errors from the worker ---
list(tr1 = errors_TR_1,
tr2 = errors_TR_2,
tr3 = errors_TR_3,
tr4 = errors_TR_4,
bm  = errors_BM)}
# --- Stop the Cluster ---
stopCluster(cl)
#-------------------------------------------------------------------
# 5. UNPACK PARALLEL RESULTS INTO STORAGE LISTS
#-------------------------------------------------------------------
# 'worker_results' is a list of P lists. We need to re-organize it.
for (i in 1:P) {
# i=1 corresponds to p=P, i=2 to p=P-1, ... i=P to p=1
# This 'storage_index' matches the loop order
storage_index <- i
# Get the list of error vectors for this 'p'
p_results <- worker_results[[i]]
# Assign the h-step error to the correct list
for (h in 1:H) {
FE_TR_1[[h]][storage_index] <- p_results$tr1[h]
FE_TR_2[[h]][storage_index] <- p_results$tr2[h]
FE_TR_3[[h]][storage_index] <- p_results$tr3[h]
FE_TR_4[[h]][storage_index] <- p_results$tr4[h]
FE_BM[[h]][storage_index]   <- p_results$bm[h]}}
#-------------------------------------------------------------------
# 6. GENERATE AND PRINT ALL FOUR REPORTS
#-------------------------------------------------------------------
# We can now just call our helper function 4 times.
# All models are compared against the same 'FE_BM' benchmark.
# Report 1: Shadowrate, No Lag
report_1 <- generate_report_table(
FE_TR_model = FE_TR_1,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on ShadowRate, No Lag",
format = format)
# Report 2: Actual Rate, No Lag
report_2 <- generate_report_table(
FE_TR_model = FE_TR_2,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on Actual Rate, No Lag",
format = format)
# Report 3: Shadowrate, with Lag
report_3 <- generate_report_table(
FE_TR_model = FE_TR_3,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on ShadowRate, with Lag",
format = format)
# Report 4: Actual Rate, with Lag
report_4 <- generate_report_table(
FE_TR_model = FE_TR_4,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on Actual Rate, with Lag",
format = format)
list(report_1, report_2, report_3, report_4)
#explain what his script does and why and how to run code in readme file
rm(list=ls())
require(tinytex) #LaTeX
require(ggplot2) #plots
require(AEC) #JP-Renne functions
require(AER) #NW formula
require(forecast) #time series forecasting
require(expm) #matrix exponents
require(here) #directory finder
require(dplyr) #data management
require(lubridate) #data dates management
require(zoo) #for lagging
require(jtools) #tables
require(huxtable) #tables
require(lmtest) #reg tests
require(vroom) #for loading data
require(data.table) #for data filtering
require(sysid) #for ARMA-X modeling
require(sandwich) #regression errors
require(stargazer) #nice reg tables
require(texreg) #arima tables
require(future.apply) #parallel computation (speed)
require(readxl) #for reading excel data
require(R.matlab) #for loading matlab data (shadowrates)
require(aTSA) #time series tests
require(eurostat) #eurostat data
require(fredr) #fredr data
require(mFilter) #HP filter
require(knitr) #tables
require(kableExtra) #tables extra
require(rdbnomics)
require(doParallel) #for speed
require(foreach)
getwd()
setwd("...")
#api for data
fredr_set_key("e0169694a62c1337f1969e3872605eca")
#dates
start_date <- "1999-01-01"
end_date <- Sys.Date()
#load helper functions
#source(here("helperfunctions/data_loaders.R"))
set.seed(2025)
format <- "html"
#format <- "latex"
#REDO THE DATA LOADING USNING rdbnomics PACKAGE (combines all macro APIs)
# --- 1. ECB Deposit Facility Rate & Shadow Rate ---
ecb_rate_daily <- fredr(series_id = "ECBDFR", observation_start = as.Date(start_date))
ecb_rate_q <- ecb_rate_daily %>%
mutate(quarter = as.yearqtr(date)) %>%
group_by(quarter) %>%
summarise(rate = last(value)) %>%
mutate(date = as.Date(quarter))
# Wu-Xia Shadow Rate
shadow_rate_daily = as.data.frame(readMat("data/shadowrate_ECB.mat"))
colnames(shadow_rate_daily) <- c("DATE", "shadowrate")
shadow_rate_daily$DATE <- as.Date(paste0(shadow_rate_daily$DATE, "01"), format="%Y%m%d")
shadow_rate_daily$quarter <- as.yearqtr(as.Date(shadow_rate_daily$DATE))
shadow_rate_daily$month <- as.yearmon(as.Date(shadow_rate_daily$DATE))
quarterly_shadow = aggregate(shadowrate ~ quarter, data=shadow_rate_daily, FUN=mean, na.rm=T)
monthly_shadow = aggregate(shadowrate ~ month, data=shadow_rate_daily, FUN=mean, na.rm=T)
# --- 2. HICP Inflation (Euro Area) ---
inflation_data <- get_eurostat("prc_hicp_manr", filters = list(geo = "EA", coicop = "CP00"), type = "label")
inflation_q <- inflation_data %>%
filter(time >= start_date) %>%
select(date = time, inflation = values) %>%
mutate(quarter = as.yearqtr(date)) %>%
group_by(quarter) %>%
summarise(inflation = mean(inflation, na.rm = TRUE)) %>%
mutate(date = as.Date(quarter))
#inflation expectations
inflation_exp <- rdb(ids = "ECB/SPF/M.U2.HICP.POINT.P12M.Q.AVG")
#inflation_exp <- rdb(ids = "ECB/SPF/M.U2.HICP.POINT.P24M.Q.AVG")
inflation_exp_q <- inflation_exp %>%
mutate(quarter = as.yearqtr(period)) %>%
group_by(quarter) %>%
summarise(exp_inflation = last(original_value)) %>%
mutate(date = as.Date(quarter))
#P12M
inflation_q$exp_inflation = c(rep(NA,3),as.numeric(inflation_exp_q$exp_inflation),NA)
#P24M
#inflation_q$exp_inflation = c(rep(NA,7),as.numeric(inflation_exp_q$exp_inflation[1:101]))
# --- 3. Real GDP and Estimated Output Gap ---
# a) Real GDP for the Euro Area. The series ID is CLVMNACSCAB1GQE_A.
gdp_q <- fredr(
series_id = "CLVMEURSCAB1GQEA19",
observation_start = as.Date(start_date)) %>%
mutate(quarter = as.yearqtr(date)) %>%
select(quarter, real_gdp = value) %>%
mutate(log_real_gdp = log(real_gdp))
# b) Estimate Potential GDP (the trend) using the HP Filter on the log of real GDP.
# The lambda value of 1600 is standard for quarterly data.
hp_gdp <- hpfilter(gdp_q$log_real_gdp, freq = 1600)
gdp_q$potential_gdp_log <- as.numeric(hp_gdp$trend)
# Combine all data into a single data frame
data <- ecb_rate_q %>%
select(quarter, rate) %>%
left_join(inflation_q, by = "quarter") %>%
left_join(gdp_q, by = "quarter") %>%
left_join(quarterly_shadow, by = "quarter")
# Create model variables
data <- data %>%
mutate(
inflation_gap = inflation - 2.0,
exp_inflation_gap = exp_inflation -2.0,
output_gap = 100 * (log_real_gdp - potential_gdp_log),
rate_lag = lag(rate, 1),
shadowrate = case_when(
quarter < "2012 Q3" | quarter >= "2022 Q3" ~ rate,
TRUE ~ shadowrate),
shadowrate_lag = lag(shadowrate, 1))
TR <- lm(rate ~ inflation_gap + output_gap, data = data)
TRsr <- lm(shadowrate ~ inflation_gap + output_gap, data = data)
TR_e <- lm(rate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)
TRsr_e <- lm(shadowrate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)
export_summs(TR, TRsr, TR_e, TRsr_e, vcov = sandwich::NeweyWest,
model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)
lTR <- lm(rate ~ rate_lag + inflation_gap + output_gap, data = data)
lTRsr <- lm(shadowrate ~ shadowrate_lag + inflation_gap + output_gap, data = data)
lTR_e <- lm(rate ~ rate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
lTRsr_e <- lm(shadowrate ~ shadowrate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
export_summs(lTR, lTRsr, lTR_e,lTRsr_e, vcov = sandwich::NeweyWest,
model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)
#parameters
R = 54-28-8-8 # start of ZLB at R=54
P = nrow(data) - R #but will effectively be: P = T-h-R
H = 12 #number of different horizons
data = subset(data, quarter < "2025 Q3")
#-------------------------------------------------------------------
# 1. DEFINE THE FOUR TAYLOR RULE (TR) MODEL FORMULAS
#-------------------------------------------------------------------
# TR based on current inflation
formula_1 <- shadowrate ~ inflation_gap + output_gap
formula_2 <- rate ~ inflation_gap + output_gap
formula_3 <- shadowrate ~ shadowrate_lag + inflation_gap + output_gap
formula_4 <- rate ~ rate_lag + inflation_gap + output_gap
# TR based on current inflation expectations of inflation in 12 months
#formula_1 <- shadowrate ~ exp_inflation_gap + output_gap
#formula_2 <- rate ~ exp_inflation_gap + output_gap
#formula_3 <- shadowrate ~ shadowrate_lag + exp_inflation_gap + output_gap
#formula_4 <- rate ~ rate_lag + exp_inflation_gap + output_gap
#-------------------------------------------------------------------
# 2. HELPER FUNCTION FOR REPORTING
#-------------------------------------------------------------------
# This function creates the DM tests and kable output
generate_report_table <- function(FE_TR_model, FE_BM_model, H, model_caption, format = "html") { MSFE_TR = numeric(H)
MSFE_BM = numeric(H)
# Calculate MSFEs
for (h in 1:H) {
# Ensure errors are cleaned of NAs
fe1 <- na.omit(FE_TR_model[[h]])
fe2 <- na.omit(FE_BM_model[[h]])
MSFE_TR[h] = mean((fe1)^2)
MSFE_BM[h] = mean((fe2)^2)}
# Run DM Tests
DMpvalues = matrix(, nrow = H, ncol = 3)
colnames(DMpvalues) <- c("DM_Two_Sided", "DM_Greater", "DM_Lesser")
for (h in 1:H){
# Note: dm.test needs the *full* (un-omitted) error vectors
# to align them properly, hence using the original list inputs
x1 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h)
x2 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h, alternative = "greater")
x3 = dm.test(e1 = FE_BM_model[[h]], e2 = FE_TR_model[[h]], h = h, alternative = "less")
DMpvalues[h, 1] = round(x1$p.value, digits = 4)
DMpvalues[h, 2] = round(x2$p.value, digits = 4)
DMpvalues[h, 3] = round(x3$p.value, digits = 4)}
# Format p-values with stars
format_p_values_with_stars <- function(p) {
stars <- case_when(
p < 0.01 ~ "***",
p < 0.05 ~ "**",
p < 0.10 ~ "*",
TRUE     ~ "")
paste0(format(round(p, 4), nsmall = 3), " ", stars)}
# Create final table data
forecast_comparison <- data.frame(
Horizon = 1:H,
MSFE_TR = MSFE_TR,
MSFE_BM = MSFE_BM) %>%
mutate(Ratio_TR_vs_BM = MSFE_TR / MSFE_BM)
forecast_comparison <- bind_cols(forecast_comparison, as.data.frame(DMpvalues))
final_data_formatted <- forecast_comparison %>%
mutate(across(starts_with("DM_"), format_p_values_with_stars))
# Create the kable table
table_output <- kable(
final_data_formatted,
format = format,
booktabs = TRUE,
caption = model_caption,
digits = 4,
col.names = c("h", "MSFE TR", "MSFE BM", "Ratio", "DM Two-Sided", "DM Greater", "DM Lesser"),
escape = FALSE) %>%
kable_styling(
latex_options = c("striped", "scale_down"),
position = "center") %>%
column_spec(1, bold = TRUE, border_right = TRUE) %>%
column_spec(5:7, monospace = TRUE) %>%
footnote(
general = "TR refers to the forecast made with an estimated Taylor Rule. BM refers to a benchmark of the interest rate using an ARIMA model. Ratio < 1 indicates that the TR model has lower MSFE.",
symbol = c(
"'DM Greater' tests if the TR model is significantly more accurate than the BM model.",
"'DM Lesser' tests if the TR model is significantly less accurate than the BM model."),
general_title = "Note:",
symbol_title = "DM Test Alternative Hypotheses (H_A):",
footnote_as_chunk = TRUE,
threeparttable = TRUE)
return(table_output)
}
#-------------------------------------------------------------------
# 3. PRE-ALLOCATE STORAGE FOR ALL RESULTS
#-------------------------------------------------------------------
# We need 4 lists for the TR models, 1 list for the shared benchmark
init_storage_list <- function(H, P) {
storage <- vector("list", length = H)
for (h in 1:H) {
storage[[h]] <- rep(NA_real_, P)}
return(storage)}
FE_TR_1 <- init_storage_list(H, P) # Model 1: shadowrate, no lag
FE_TR_2 <- init_storage_list(H, P) # Model 2: rate, no lag
FE_TR_3 <- init_storage_list(H, P) # Model 3: shadowrate, with lag
FE_TR_4 <- init_storage_list(H, P) # Model 4: rate, with lag
FE_BM   <- init_storage_list(H, P) # Benchmark: ARIMA
#-------------------------------------------------------------------
# 4. SETUP & RUN THE PARALLEL BACKTESTING LOOP
#-------------------------------------------------------------------
num_cores <- detectCores() - 1
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# .export sends read-only objects to each core
# .packages loads libraries on each core
worker_results <- foreach(
p = P:1,
.packages = c("forecast", "stats", "dplyr"),
.export = c("data", "H", "formula_1", "formula_2", "formula_3", "formula_4")
) %dopar% {
# 1. Define splits
training <- data[1:(nrow(data) - p), ]
testing <- data[(nrow(data) - (p - 1)):nrow(data), ]
# --- 2. Fit common models only once ---
inflation_arma <- auto.arima(training$inflation_gap, max.p=4, max.q=4, max.d=1)
#exp_inflation_arma <- auto.arima(training$exp_inflation_gap, max.p=4, max.q=4, max.d=1)
outputgap_arma <- auto.arima(training$output_gap, max.p=4, max.q=4, max.d=1)
interest_arma <- auto.arima(training$rate, max.p=4, max.q=4, max.d=1) # Benchmark
# --- 3. Get common forecasts only once (all H horizons) ---
inflation_forecasts <- forecast::forecast(inflation_arma, h = H)$mean
#exp_inflation_forecasts <- forecast::forecast(exp_inflation_arma, h = H)$mean
outputgap_forecasts <- forecast::forecast(outputgap_arma, h = H)$mean
BMpredicted_rates <- forecast::forecast(interest_arma, h = H)$mean
# --- 4. Fit the 4 SPECIFIC TR models ---
TR_model_1 <- lm(formula_1, data = training)
TR_model_2 <- lm(formula_2, data = training)
TR_model_3 <- lm(formula_3, data = training)
TR_model_4 <- lm(formula_4, data = training)
# --- 5. Build forecast input data frames ---
# Base inputs (for Models 1 & 2)
new_data_base <- data.frame(
inflation_gap = inflation_forecasts,
#exp_inflation_gap = exp_inflation_forecasts,
output_gap = outputgap_forecasts)
# Inputs for Model 3 (needs shadowrate_lag)
new_data_3 <- data.frame(
new_data_base,
shadowrate_lag = testing$shadowrate_lag[1:H])
# Inputs for Model 4 (needs rate_lag)
new_data_4 <- data.frame(
new_data_base,
rate_lag = testing$rate_lag[1:H])
# --- 6. Get H-step forecasts for all 5 models ---
TR_preds_1 <- pmax(predict(TR_model_1, new_data_base), min(data$rate))
TR_preds_2 <- pmax(predict(TR_model_2, new_data_base), min(data$rate))
TR_preds_3 <- pmax(predict(TR_model_3, new_data_3), min(data$rate))
TR_preds_4 <- pmax(predict(TR_model_4, new_data_4), min(data$rate))
BM_preds   <- pmax(BMpredicted_rates, min(data$rate)) # Benchmark
# --- 7. Compute errors against actuals ---
actual_rates <- testing$rate[1:H]
errors_TR_1 <- TR_preds_1 - actual_rates
errors_TR_2 <- TR_preds_2 - actual_rates
errors_TR_3 <- TR_preds_3 - actual_rates
errors_TR_4 <- TR_preds_4 - actual_rates
errors_BM   <- BM_preds   - actual_rates
# --- 8. Return all errors from the worker ---
list(tr1 = errors_TR_1,
tr2 = errors_TR_2,
tr3 = errors_TR_3,
tr4 = errors_TR_4,
bm  = errors_BM)}
# --- Stop the Cluster ---
stopCluster(cl)
#-------------------------------------------------------------------
# 5. UNPACK PARALLEL RESULTS INTO STORAGE LISTS
#-------------------------------------------------------------------
# 'worker_results' is a list of P lists. We need to re-organize it.
for (i in 1:P) {
# i=1 corresponds to p=P, i=2 to p=P-1, ... i=P to p=1
# This 'storage_index' matches the loop order
storage_index <- i
# Get the list of error vectors for this 'p'
p_results <- worker_results[[i]]
# Assign the h-step error to the correct list
for (h in 1:H) {
FE_TR_1[[h]][storage_index] <- p_results$tr1[h]
FE_TR_2[[h]][storage_index] <- p_results$tr2[h]
FE_TR_3[[h]][storage_index] <- p_results$tr3[h]
FE_TR_4[[h]][storage_index] <- p_results$tr4[h]
FE_BM[[h]][storage_index]   <- p_results$bm[h]}}
#-------------------------------------------------------------------
# 6. GENERATE AND PRINT ALL FOUR REPORTS
#-------------------------------------------------------------------
# We can now just call our helper function 4 times.
# All models are compared against the same 'FE_BM' benchmark.
# Report 1: Shadowrate, No Lag
report_1 <- generate_report_table(
FE_TR_model = FE_TR_1,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on ShadowRate, No Lag",
format = format)
# Report 2: Actual Rate, No Lag
report_2 <- generate_report_table(
FE_TR_model = FE_TR_2,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on Actual Rate, No Lag",
format = format)
# Report 3: Shadowrate, with Lag
report_3 <- generate_report_table(
FE_TR_model = FE_TR_3,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on ShadowRate, with Lag",
format = format)
# Report 4: Actual Rate, with Lag
report_4 <- generate_report_table(
FE_TR_model = FE_TR_4,
FE_BM_model = FE_BM,
H = H,
model_caption = "MSFE Comparison, Trained on Actual Rate, with Lag",
format = format)
list(report_1, report_2, report_3, report_4)
??pmax
?'pmax'
View(FE_TR_1)
FE_BM[[Â¦]]
FE_BM[[1]]
FE_BM[[12]]
View(cl)
# Clean environment
rm(gdp_q, hp_gdp, ecb_rate_daily, ecb_rate_q, inflation_data, inflation_q,
inflation_exp, inflation_exp_q, monthly_shadow, quarterly_shadow, shadow_rate_daily)
lTR_e <- lm(rate ~ rate_lag + exp_inflation_gap + output_gap, data = data)
lTRsr_e <- lm(shadowrate ~ shadowrate_lag + exp_inflation_gap + output_gap, data = data)
lTR_ie <- lm(rate ~ rate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
lTRsr_ie <- lm(shadowrate ~ shadowrate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
export_summs(lTR_ie, lTRsr_ie, lTR_e,lTRsr_e, vcov = sandwich::NeweyWest,
model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)
lTR_e <- lm(rate ~ rate_lag + exp_inflation_gap + output_gap, data = data)
lTRsr_e <- lm(shadowrate ~ shadowrate_lag + exp_inflation_gap + output_gap, data = data)
lTR_ie <- lm(rate ~ rate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
lTRsr_ie <- lm(shadowrate ~ shadowrate_lag + inflation_gap + exp_inflation_gap + output_gap, data = data)
export_summs(lTR_e, lTRsr_e, lTR_ie,lTRsr_ie, vcov = sandwich::NeweyWest,
model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)
TR_e <- lm(rate ~ exp_inflation_gap + output_gap, data = data)
TRsr_e <- lm(shadowrate ~ exp_inflation_gap + output_gap, data = data)
TR_ie <- lm(rate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)
TRsr_ie <- lm(shadowrate ~ inflation_gap + exp_inflation_gap + output_gap, data = data)
export_summs(TR_e, TRsr_e, TR_ie, TRsr_ie, vcov = sandwich::NeweyWest,
model.names = c("TR", "TR w/ SR", "TR", "TR w/ SR"), digits = 4)
