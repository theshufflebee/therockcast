---
title: "ECB Project"
output:
  pdf_document: 
    toc: true
    fig_caption: yes
    toc_depth: 3
    latex_engine: lualatex
    keep_tex: false
header-includes:
  - \usepackage{amsmath}
  - \usepackage[backend=biber,style=authoryear]{biblatex}  # load biblatex
  - \addbibresource{citations.bib}  # BibTeX file
---
\newpage

# Preliminaries

## Setup
```{r setup, results=FALSE, warning=FALSE, message=FALSE, echo=TRUE}

# --------- 1. Clear memory
rm(list=ls())

# --------- 2. Load here package to enable finding script loading other packages 
require(here)

# --------- 3. Set directory
getwd()
setwd("...") 

# --------- 4. Load packages & helper functions for plots and tables
source(here("scripts/packages.R"))
source(here("helpers/raw_plotter.R"))
source(here("helpers/stationarity_tables.R"))
source(here("helpers/taylor_tables.R"))
source(here("helpers/struct_breaks_tables.R"))
source(here("helpers/roll_TR_plotter.R"))
source(here("helpers/pseudo_outofsample_tables.R"))
source(here("helpers/pseudo_outofsample_plots.R"))
source(here("helpers/actual_forecast_displays.R"))

# Api key for data
fredr_set_key("e0169694a62c1337f1969e3872605eca")

# --------- 5. Dates (to automatically get the latest data from API calls
start_date <- "1999-01-01"
end_date <- Sys.Date()

# For replication 
set.seed(2025)

```

## Interactive Option Selection

* Use Hamilton Filter: 
  + TRUE: Selects Hamilton method for output gap estimation
  + FALSE: Selects Hodrick-Prescott method for output gap estimation

* Use Inflation Expectations:
  + TRUE: The models used for forecasting will use 12-month ahead inflation
          expectations from the ECB survey of professional forecasts (average).
  + FALSE: The models used for forecasting will use realised inflation
  
* Use Formula
  + Formula 1: Actual interest rate regressed on inflation and output gaps  
  + Formula 2: Shadow interest rate regressed on inflation and output gaps
  + Formula 3: Actual interest rate regressed on the one-quarter lag of the interest
                rate and on inflation and output gaps
  + Formula 4: Shadow interest rate regressed on the one-quarter lag of the shadow 
                interest rate and on inflation and output gaps
                
* Format:
  + html: For outputting in console or knitting to html
  + latex: For knitting to pdf

```{r options, results=FALSE, warning=FALSE, message=FALSE, echo=TRUE}

source(here("scripts/options_config.R"))

#temp remove soon
format <- "html"
#format <- "latex" 

```

```{r taylor-rule-formulas, echo=TRUE, message=FALSE, warning=FALSE}

source(here("scripts/taylor_rule_formulas.R"))

```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

# Data

## Sources \& Explanations

* FRED Data Source: European Central Bank, ECB Deposit Facility Rate for Euro 
                    Area [ECBDFR], retrieved from FRED, Federal Reserve Bank of 
                    St. Louis; https://fred.stlouisfed.org/series/ECBDFR. 
                    The data is the Deposit Facility and is directly reprinted 
                    from the ECB. It's in Percent and not seasonally adjusted. 
                    The ECB Monetary Policy is steered through this rate

* Shadow Interest Rate: The Shadow rate was developed by 
                        \cite{wuTimeVaryingLowerBound2017} and does quantify 
                        a hypothetical removal of the ZLB. The rate does not 
                        track 1:1 on the deposit facility in the data before 
                        the ZLB, instead being closer to the refinancing rate. 
                        (maybe need to adjust)

* GDP: The GDP Data is quarterly real GDP in 2010 Euros in million retrieved from FRED 
       via Eurostat. The data is seasonally adjusted.

* Potential GDP: Either estimated with the Hodrick-Prescott filter or the Hamilton filter, based on the formula below:
    $$
      \begin{aligned}
      \text{HP Filter:} \quad & \min_{\tau} \left( \sum_{t=1}^{T} (y_t - \tau_t)^2 + \lambda \sum_{t=2}^{T-1} \left[ (\tau_{t+1} - \tau_t) - (\tau_t - \tau_{t-1}) \right]^2 \right) \\
      \text{Hamilton:} \quad & y_t = \beta_0 + \sum_{j=1}^{p} \beta_j y_{t-h-j+1} + v_t \quad \text{(where } v_t \text{ is the cycle)}
      \end{aligned}
    $$

* Inflation:
  + Realised: The Inflation data is from Eurostat and measures HICP monthly data (annual rate of change). It's the index that the ECB uses for Inflation and is not seasonally adjusted, but the 
    fact that it represents the year-on-year change in prices implies there is no seasonality.
  + Expectations: Expected Inflation is the ECB's survey of professional 
    forecasters. It forecasts the HICP 12 months in advance.


## Loading \& Preparation Data 
```{r data, echo=TRUE, message=FALSE, warning=FALSE}

#copypaste data script and explain
source(here("scripts/data.R"))

```

## Options Configuration
```{r data_config, message=TRUE, warning=FALSE, results='asis'}

source(here("scripts/options_implement.R"))

```

## Raw Data Plots
```{r data_plots, message=FALSE, warning=FALSE}

# Who cares about the method here, only result matters 
raw_data_plotter(data = data)

```

## Data Properties
```{r stat_tests_func, echo=TRUE, message=FALSE, warning=FALSE}

# copy paste both stat and coint funcs and explain
source(here("helpers/stationarity_tests.R"))

```


```{r data_prop, echo=TRUE, message=FALSE, warning=FALSE}

# -----  Run Tests -----

# Use helper to run stationarity checks for our main variables
test_rate <- check_stationarity(data$rate, "Interest Rate")
test_inflation <- check_stationarity(data$inflation, "Inflation")
test_output_gap <- check_stationarity(na.omit(data$output_gap), "Output Gap")

# Given results for rate and inflation, run tests on 1st diffs
test_rate_diff <- check_stationarity(diff(data$rate), "Interest Rate (1st Diff)")
test_inflation_diff <- check_stationarity(diff(data$inflation), "Inflation (1st Diff)")

# Since rate and inflation are I(1), run a cointegration test
coint_test = check_coint(data$rate, data$inflation, 
            var_name1 = "Interest Rate", var_name2 = "Inflation")


# ----- Print Results -----

# Combine stationarity results 
all_stationarity_results <- rbind(test_rate, 
                                  test_inflation, 
                                  test_output_gap,
                                  test_rate_diff,
                                  test_inflation_diff)

# Tables
generate_stat_tests_table(stat_tests = all_stationarity_results)
generate_coint_tests_table(coint_test = coint_test)

# Cleanup
rm(all_stationarity_results, coint_test, test_inflation, 
   test_inflation_diff, test_output_gap, test_rate, test_rate_diff)

```


```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

# Taylor Rule Estimation

## Without Lags
$$
\begin{aligned}
  i_t &= \pi^* + \beta(\pi_t-\pi^*) + \gamma(y_t-\bar{y_t})  \\
\end{aligned}
$$

```{r Taylor Rule simple w/o lag}

TR <- lm(rate ~ realised_inflation_gap + output_gap, data = data)
TRsr <- lm(shadowrate ~ realised_inflation_gap + output_gap, data = data)

models <- list(TR, TRsr)
taylor_regression_to_table(models, caption = "No Lag, No Expectations")

```

```{r Taylor Rule simple w/o lag but with inflatione expectations}

TR_e <- lm(rate ~ exp_inflation_gap + output_gap, data = data)
TRsr_e <- lm(shadowrate ~ exp_inflation_gap + output_gap, data = data)
TR_ie <- lm(rate ~ realised_inflation_gap + exp_inflation_gap + 
                   output_gap, data = data)
TRsr_ie <- lm(shadowrate ~ realised_inflation_gap + exp_inflation_gap + 
                           output_gap, data = data)

models <- list(TR_e, TRsr_e, TR_ie, TRsr_ie)
taylor_regression_to_table(models, caption = "No Lag, with 
                                              Inflation Expectations")

```


## Lagged Models 
$$
\begin{aligned}
     i_t &= \pi^* + \phi i_{t-1} + \beta (\pi_t-\pi^*) + \gamma(y_t-\bar{y_t}) 
\end{aligned}
$$

```{r Taylor Rule simple w/ lag}

lTR <- lm(rate ~ rate_lag + realised_inflation_gap + output_gap, data = data)
lTRsr <- lm(shadowrate ~ shadowrate_lag + realised_inflation_gap + 
                         output_gap, data = data)

models <- list(lTR, lTRsr)
taylor_regression_to_table(models, caption = "Interest Rate Lag, 
                                              No Expectations")

```

```{r Taylor Rule simple w/ lag and inflation expectations}

lTR_e <- lm(rate ~ rate_lag + exp_inflation_gap + output_gap, data = data)
lTRsr_e <- lm(shadowrate ~ shadowrate_lag + exp_inflation_gap + 
                           output_gap, data = data)
lTR_ie <- lm(rate ~ rate_lag + realised_inflation_gap + exp_inflation_gap + 
                    output_gap, data = data)
lTRsr_ie <- lm(shadowrate ~ shadowrate_lag + realised_inflation_gap + 
                            exp_inflation_gap + output_gap, data = data) 

models <- list(lTR_e, lTRsr_e, lTR_ie, lTRsr_ie)
taylor_regression_to_table(models, caption = "Interest Rate Lag, with 
                                              Inflation Expectations")

```

## Checking for structural breaks
```{r chowtest}

#only paste chow one
source(here("helpers/struct_breaks_tests.R"))

# 1st Suspected break: Start of ZLB in 2012 Q3
#  -> R = 55 in evaluation chunk

# Suspected break: Covid
#  -> R = 85 in evaluation chunk

# Run test using helper function 
chow_tests(data, break1 = 55, break2 = 85, 
           events_name <- c("ZLB Start", "COVID-19 Start"))  


```

```{r bai-perron test}

#only paste bp one
source(here("helpers/struct_breaks_tests.R"))

# Run test using helper function 
bp_tests(data)

```






## Rolling Estimation (for structural breaks)
```{r rolling TR, message=FALSE, warning=FALSE}

source(here("helpers/roll_TR_estimator.R"))

# Estimate a rolling-window (W in quarters) Taylor Rule specification
TR_roll <- estimate_rolling_TR(data, W = 30)

# Plotting (note: this part is not modular, obviously)
plot_rolling_coefs(TR_roll, "rate_lag", var_name_title="Rate Lag")
plot_rolling_coefs(TR_roll, "inflation_gap", var_name_title="Inflation (Gap)")
plot_rolling_coefs(TR_roll, "output_gap", var_name_title="Output Gap")

```


```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```


# Forecasting Model Evaluation

## Methods
Describe method with auto arima and so on.
```{r auto_arima_func, echo=TRUE, message=FALSE, warning=FALSE}

source(here("helpers/auto_ARIMA_replic.R"))

```


## Pseudo Out of Sample Estimation

Pseudo-out of sample rolling estimation scheme of direct forecasts for all
Taylor Rule formulas and a benchmark ARIMA specification. 



```{r pseudo-out-of-sample-parameters, echo=TRUE, message=FALSE, warning=FALSE}

#add explain parameters
R = 85 # Chow: Structural breaks at R=55 and R=85 
cat("Evaluation sample starts after ",as.character(data$quarter[R]),".",sep="")
P = nrow(data) - R #but will effectively be: P = T-h-R
H = 10 # Number of different horizons (takes 10 to go until 2027 Q4)

```


```{r pseudo-out-of-sample-estimation, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

source(here("scripts/pseudo_out_of_sample_estimation.R"))

```

## Spaghetti Plots
```{r Spaghetti Plot, message=FALSE, warning=FALSE}

spaghetti_plotter(evals = eval_all_models)

```

## Forecast Errors 

### Plots of FE
```{r Plot of Forecast Errors, warning=FALSE, message=FALSE}

FE_spaghetti_plotter(evals = eval_all_models)

```

### Density of FE
```{r Density of Forecast Errors}

FE_density_plotter_unscaled(evals = eval_all_models)
FE_density_plotter_scaled(evals = eval_all_models)
FE_density_plotter_ridges(evals = eval_all_models)

```

### Variance of FE
```{r Variance of Forecast Errors}

FE_variance_plotter(var_by_horizon)

```

### Horizon 1 Autocorrelation of FE
Mmodel 1, 2, 3 are autocorrelated at h=1. 
```{r Durbin Watson test, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

#Durbin Watson tests for first autocorrelation at h=1

# Select Forecast Columns
formula_cols <- grep("^F_TR_FORMULA_", names(eval_all_models), value = TRUE)

# Automatically set max horizon for loop
max_h <- max(eval_all_models$horizon)

# Loop for each model
for (e_model_name in formula_cols) {

  # Extract and regress errors
  all_forecast_errors <- eval_all_models[["actuals"]] - eval_all_models[[e_model_name]]
  h1_errors_vector <- all_forecast_errors[eval_all_models$horizon == 1]
  temp_model <- lm(h1_errors_vector ~ 1)

  # Durbin-Watson Test
  dw_test_result <- durbinWatsonTest(temp_model)

  # Print output
  cat(sprintf("\n--- Durbin-Watson Test for Model: %s (h=1) ---\n", e_model_name))
  print(dw_test_result)
  cat(sprintf("DW Statistic: %.4f\n", dw_test_result$statistic))}

```


### Overall Autocorrelation of FE
We don't reject H0 -> h+1 are uncorrelated
1,2, are autocorrelated, 3 and 4 arent

```{r Ljung Box test, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

#Ljung Box Test, with Columns & max lags set in Durbin Watson code chunk

# Loop through each TR
for (e_model_name in formula_cols) {
    
    cat(sprintf("--- Checking Errors for Model: %s ---\n", e_model_name))
    
    # Calculate the errors of the model
    all_errors <- eval_all_models[["actuals"]] - eval_all_models[[e_model_name]]
    
    # Loop over all forecast horizons to test for autocorrelation
    for (h in 1:max_h){
        
        # select errors for each horizon
        h_errors <- all_errors[eval_all_models$horizon == h]
            
        # max lag according to slides around sqrt T
        T_errors <- length(h_errors)
        max_lag <- 4 #round(sqrt(T_errors)) # use 4 or 5 chose 4 because 1 year has 4 quarters
        
        # Ljung-Box Test
        lb_test_result <- Box.test(h_errors, 
                                   lag = max_lag, 
                                   type = "Ljung-Box")
        
        #Print Results
        cat(sprintf("Horizon h=%d (N=%d, Lags=%d): Q=%.2f, p-value=%.3f\n", 
                    h, T_errors, max_lag, lb_test_result$statistic, lb_test_result$p.value))}
        cat("\n")}

```

### Errors Normally Distributed
Run the Jarque Bera Test with helpers

```{r jb_test_func, echo=TRUE, message=TRUE, warning=FALSE}

# in final markdown, input just the relevant code, i.e. the tests made
# who cares about code to create tables, that stays in helpers
source(here("helpers/pseudo_outofsample_tests.R"))

```

```{r Jarque Bera Test, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Run with helper functions
# missing benchmark
generate_all_jb_reports(
  formula_cols =  formula_cols,
  eval_all_models = eval_all_models,
  max_h = max_h)

```




## Absolute Performance: Efficiency \& Bias
```{r mz_test_func, echo=TRUE, message=TRUE, warning=FALSE}

# in final markdown, input just the relevant code, i.e. the tests made
# who cares about code to create tables, that stays in helpers
source(here("helpers/pseudo_outofsample_tests.R"))

```


```{r forecast-model-efficiency, echo=TRUE, message=TRUE, warning=FALSE, results='asis'}

# Call MZ-test helper function 4 times.
#  Note: These reports is wrapped in trycatch as it sometimes fails
#         If it does fail, simply decrease R in order to have more 
#          observations, removing potential multicolinearity.

# MZ Report 1: Actual Rate, No Lag
mz_report_1 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_1,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Actual Rate, No Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Actual Rate, No Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 2: Shadow Rate, No Lag (
mz_report_2 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_2,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Shadow Rate, No Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Shadow Rate, No Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 3: Actual Rate, with Lag
mz_report_3 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_3,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Actual Rate, with Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Actual Rate, with Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 4: Shadow Rate, with Lag
mz_report_4 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_4,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Shadow Rate, with Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Shadow Rate, with Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 5: Benchmark
mz_report_BM <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_BM,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Benchmark ARIMA",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Benchmark ARIMA): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

list(mz_report_1, mz_report_2, mz_report_3, mz_report_4, mz_report_BM)

```


## Relative Performance (against benchmark)
```{r dm_test_func, echo=TRUE, message=TRUE, warning=FALSE}

# in final markdown, input just the relevant code, i.e. the tests made
# who cares about code to create tables, that stays in helpers
source(here("helpers/pseudo_outofsample_tests.R"))

```

```{r forecast-model-perf, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Call DM-test helper function 4 times.

# Report 1: Actual Rate, No Lag
report_1 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_1,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, No Lag",
  format = format)

# Report 2: Shadow Rate, No Lag
report_2 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_2,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Shadow Rate, No Lag",
  format = format)

# Report 3: Actual Rate, with Lag
report_3 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_3,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, with Lag",
  format = format)

# Report 4: Shadow Rate, with Lag
report_4 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_4,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Shadow Rate, with Lag",
  format = format)

list(report_1, report_2, report_3, report_4)

```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```



# Actual Forecast Model

## Forecasting
```{r forecast, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

source(here("helpers/actual_forecast_estimator.R"))

final_forecasts <- our_predict(data = data, formula = model_formula, H = H)
 
display_forecasts(final_forecasts, 
                  caption = paste("For model based on:", model_name),
                  format = format)

plot_forecasts(final_forecasts)
 
```

## Prediction Intervals

Prepare Data
```{r prediction_intervals, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

source(here("helpers/actual_forecast_estimator.R"))

# Computes prediction intervals
final_interval <- our_predict_intervals(estimated_variance = var_by_horizon,
                                        forecast = final_forecasts)

# Plots prediction intervals
plot_forecasts_pred_int(data, intervals = final_interval)

```















