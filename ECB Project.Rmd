---
title: "ECB Project - Coding Appendix"
output:
  pdf_document: 
    toc: true
    fig_caption: yes
    toc_depth: 3
    latex_engine: lualatex
    keep_tex: false
header-includes:
  - \usepackage{amsmath}
  - \usepackage{hyperref}
  - \usepackage[backend=biber,style=authoryear]{biblatex}  
  - \addbibresource{citations.bib}  # BibTeX file
---
\newpage

# Preliminaries

## Setup
```{r setup, results=FALSE, warning=FALSE, message=FALSE, echo=TRUE}

# --------- 1. Clear memory
rm(list=ls())

# --------- 2. Load here package to enable finding script loading other packages 
require(here)

# --------- 3. Set directory
getwd()
setwd("...") 

# --------- 4. Load packages & helper functions for plots and tables
source(here("scripts/packages.R"))
source(here("helpers/raw_plotter.R"))
source(here("helpers/stationarity_tables.R"))
source(here("helpers/taylor_tables.R"))
source(here("helpers/struct_breaks_tables.R"))
source(here("helpers/roll_TR_plotter.R"))
source(here("helpers/pseudo_outofsample_tables.R"))
source(here("helpers/pseudo_outofsample_plots.R"))
source(here("helpers/actual_forecast_displays.R"))

# Api key for data
fredr_set_key("e0169694a62c1337f1969e3872605eca")

# --------- 5. Dates (to automatically get the latest data from API calls
start_date <- "1999-01-01"
end_date <- Sys.Date()

# For replication 
set.seed(2025)

```

## Interactive Option Selection

* Use Hamilton Filter: 
  + TRUE: Selects Hamilton method for output gap estimation
  + FALSE: Selects Hodrick-Prescott method for output gap estimation

* Use Inflation Expectations:
  + TRUE: The models used for forecasting will use 12-month ahead inflation
          expectations from the ECB survey of professional forecasts (average).
  + FALSE: The models used for forecasting will use realised inflation
  
* Use Formula
  + Formula 1: Actual interest rate regressed on inflation and output gaps  
  + Formula 2: Shadow interest rate regressed on inflation and output gaps
  + Formula 3: Actual interest rate regressed on the one-quarter lag of the interest
                rate and on inflation and output gaps
  + Formula 4: Shadow interest rate regressed on the one-quarter lag of the shadow 
                interest rate and on inflation and output gaps
                
* Format:
  + html: For outputting in console or knitting to html
  + latex: For knitting to pdf

```{r options, results=FALSE, warning=FALSE, message=FALSE, echo=TRUE}

source(here("scripts/options_config.R"))

#temp remove soon
format <- "html"
format <- "latex" 

```

```{r taylor-rule-formulas, echo=TRUE, message=FALSE, warning=FALSE}

source(here("scripts/taylor_rule_formulas.R"))

```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

# Data

## Sources \& Explanations

* FRED Data Source: European Central Bank, ECB Deposit Facility Rate for Euro 
                    Area [ECBDFR], retrieved from FRED, Federal Reserve Bank of 
                    St. Louis; https://fred.stlouisfed.org/series/ECBDFR. 
                    The data is the Deposit Facility and is directly reprinted 
                    from the ECB. It's in Percent and not seasonally adjusted. 
                    The ECB Monetary Policy is steered through this rate

* Shadow Interest Rate: The Shadow rate was developed by 
                        \cite{wuTimeVaryingLowerBound2017} and does quantify 
                        a hypothetical removal of the ZLB. The rate does not 
                        track 1:1 on the deposit facility in the data before 
                        the ZLB, instead being closer to the refinancing rate. 
                        (maybe need to adjust, oui je crois faux, surtout la partie
                        sur refinancing rate)

* GDP: The GDP Data is quarterly real GDP in 2010 Euros in million retrieved from FRED 
       via Eurostat. The data is seasonally adjusted.

* Potential GDP: Either estimated with the Hodrick-Prescott filter or the Hamilton filter, based on the formula below:
    $$
      \begin{aligned}
      \text{HP Filter:} \quad & \min_{\tau} \left( \sum_{t=1}^{T} (y_t - \tau_t)^2 + \lambda \sum_{t=2}^{T-1} \left[ (\tau_{t+1} - \tau_t) - (\tau_t - \tau_{t-1}) \right]^2 \right) \\
      \text{Hamilton:} \quad & y_t = \beta_0 + \sum_{j=1}^{p} \beta_j y_{t-h-j+1} + v_t \quad \text{(where } v_t \text{ is the cycle)}
      \end{aligned}
    $$

* Inflation:
  + Realised: The Inflation data is from Eurostat and measures HICP monthly data (annual rate of change). It's the index that the ECB uses for Inflation and is not seasonally adjusted, but the 
    fact that it represents the year-on-year change in prices implies there is no seasonality.
  + Expectations: Expected Inflation is the ECB's survey of professional 
    forecasters. It tracks professional forecasts of HICP inflation 12 months in advance.


## Loading \& Preparation Data 
To get this data, we run the following code using API calls to FRED, EuroStat, and
DBnomics. We convert each variable to the quarterly average and then store them all
to one dataframe named "data". It includes a date column, the deposit rate, the shadow
rate, inflation, inflation gap (which is just inflation minus the ECB target, which is
set at 2\%), expected inflation, expected inflation gap, real GDP, GDP output gap 
computed with the HP filter and GDP output gap computed with the Hamilton filter.
```{r data, echo=TRUE, message=FALSE, warning=FALSE}

#copypaste data script and explain
source(here("scripts/data.R"))

```

## Options Configuration
We then implement the chosen options on using inflation expectations or not, and
on using either the HP filter or the Hamilton filter for output gap.
```{r data_config, message=TRUE, warning=FALSE, results='asis'}

source(here("scripts/options_implement.R"))

```

## Raw Data Plots
```{r data_plots, message=FALSE, warning=FALSE}

# Who cares about the method here, only result matters 
raw_data_plotter(data = data)

```

## Data Properties
In this section, we run various tests to understand the properties of our main variables,
interest rate, inflation and output gap.
These include both ADF and KPSS stationarity tests (using the tseries package) and a cointegration test (using the aTSA package) to see if the interest rate is 
cointegrated with inflation. We wrap these in custom functions that automatically report
the results and intepret them based on the relevant p-value.
```{r stat_tests_func, echo=TRUE, message=FALSE, warning=FALSE}

# copy paste both stat and coint funcs and explain
source(here("helpers/stationarity_tests.R"))

```


```{r data_prop, echo=TRUE, message=FALSE, warning=FALSE}

# -----  Run Tests -----

# Use helper to run stationarity checks for our main variables
test_rate <- check_stationarity(data$rate, "Interest Rate")
test_inflation <- check_stationarity(data$inflation, "Inflation")
test_output_gap <- check_stationarity(na.omit(data$output_gap), "Output Gap")

# Given results for rate and inflation, run tests on 1st diffs
test_rate_diff <- check_stationarity(diff(data$rate), "Interest Rate (1st Diff)")
test_inflation_diff <- check_stationarity(diff(data$inflation), "Inflation (1st Diff)")

# Since rate and inflation are I(1), run a cointegration test
coint_test = check_coint(data$rate, data$inflation, 
            var_name1 = "Interest Rate", var_name2 = "Inflation")


# ----- Print Results -----

# Combine stationarity results 
all_stationarity_results <- rbind(test_rate, 
                                  test_inflation, 
                                  test_output_gap,
                                  test_rate_diff,
                                  test_inflation_diff)

# Tables
generate_stat_tests_table(stat_tests = all_stationarity_results)
generate_coint_tests_table(coint_test = coint_test)

# Cleanup
rm(all_stationarity_results, coint_test, test_inflation, 
   test_inflation_diff, test_output_gap, test_rate, test_rate_diff)

```


```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

# Taylor Rule Estimation
We now run basic Taylor Rule estimations using OLS on the complete dataset in order
to get some information on the historical Taylor coefficients.

## Without Lags
The "No Lag" Taylor Rule specifications follow the regression expressed in equation \eqref{eq:nolagTR}. We run 6 variations total of this, starting with the base case
using the actual deposit rate, realised inflation (gap) and the output gap. We then 
mix cases where we use the shadow rate, expected inflation (gap) and finally including
both expected and realised inflation (gap).

\begin{equation} 
\begin{aligned}
  i_t &= \pi^* + \beta(\pi_t-\pi^*) + \gamma(y_t-\bar{y_t}) 
\end{aligned}
\label{eq:nolagTR}
\end{equation}

```{r Taylor Rule simple w/o lag, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

TR <- lm(rate ~ realised_inflation_gap + output_gap, data = data)
TRsr <- lm(shadowrate ~ realised_inflation_gap + output_gap, data = data)

models <- list(TR, TRsr)
taylor_regression_to_table(models, caption = "No Lag, No Expectations")

```

```{r Taylor Rule simple w/o lag but with inflatione expectations, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

TR_e <- lm(rate ~ exp_inflation_gap + output_gap, data = data)
TRsr_e <- lm(shadowrate ~ exp_inflation_gap + output_gap, data = data)
TR_ie <- lm(rate ~ realised_inflation_gap + exp_inflation_gap + 
                   output_gap, data = data)
TRsr_ie <- lm(shadowrate ~ realised_inflation_gap + exp_inflation_gap + 
                           output_gap, data = data)

models <- list(TR_e, TRsr_e, TR_ie, TRsr_ie)
taylor_regression_to_table(models, caption = "No Lag, with 
                                              Inflation Expectations")

```


## Lagged Models 
The lagged Taylor Rule specifications follow the regression expressed in equation \eqref{eq:lagTR} which is the same as \eqref{eq:nolagTR} but also including a 
one-quarter lag for the interest rate. We then run the same 6 variations as for 
the models without the lag.

\begin{equation} 
\begin{aligned}
  i_t &= \pi^* + \phi i_{t-1} + \beta (\pi_t-\pi^*) + \gamma(y_t-\bar{y_t})
\end{aligned}
\label{eq:lagTR}
\end{equation}

```{r Taylor Rule simple w/ lag, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

lTR <- lm(rate ~ rate_lag + realised_inflation_gap + output_gap, data = data)
lTRsr <- lm(shadowrate ~ shadowrate_lag + realised_inflation_gap + 
                         output_gap, data = data)

models <- list(lTR, lTRsr)
taylor_regression_to_table(models, caption = "Interest Rate Lag, 
                                              No Expectations")

```

```{r Taylor Rule simple w/ lag and inflation expectations, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

lTR_e <- lm(rate ~ rate_lag + exp_inflation_gap + output_gap, data = data)
lTRsr_e <- lm(shadowrate ~ shadowrate_lag + exp_inflation_gap + 
                           output_gap, data = data)
lTR_ie <- lm(rate ~ rate_lag + realised_inflation_gap + exp_inflation_gap + 
                    output_gap, data = data)
lTRsr_ie <- lm(shadowrate ~ shadowrate_lag + realised_inflation_gap + 
                            exp_inflation_gap + output_gap, data = data) 

models <- list(lTR_e, lTRsr_e, lTR_ie, lTRsr_ie)
taylor_regression_to_table(models, caption = "Interest Rate Lag, with 
                                              Inflation Expectations")

```

## Checking for structural breaks
The previous Taylor Rule estimation are most likely flawed if there have been 
structural breaks in the economic system that would influence the way the ECB reacts
to the economy. Given this, we run both a Chow test and a Bai-Perron test in order
to see if there are any using the "strucchange" package. The Chow test is run on 
two dates where we suspect therehave been breaks which are in the third quarter of 
2012, representing the start 
of the Zero Lower Bound, and in the first quarter of 2020, representing the start
of the COVID-19 pandemic. The Bai-Perron test, however, works by finding any
structural breaks present in the overall sample \textcolor{red}{which minimise
the Aikake Information Criterion}. 

```{r chowtest, echo=TRUE, message=FALSE, warning=FALSE}

#only paste chow one
source(here("helpers/struct_breaks_tests.R"))

# 1st Suspected break: Start of ZLB in 2012 Q3
#  -> R = 55 in evaluation chunk

# Suspected break: Covid in 2020 Q1
#  -> R = 85 in evaluation chunk

# Run test using helper function 
chow_tests(data, break1 = 55, break2 = 85, 
           events_name <- c("ZLB Start", "COVID-19 Start"))  


```

```{r bai-perron test}

#only paste bp one
source(here("helpers/struct_breaks_tests.R"))

# Run test using helper function 
bp_tests(data)

```



## Rolling Estimation 
Given that there have been structural breaks (according to our tests), we decide 
to run a rolling estimation scheme for the Taylor Rule formula selected in the 
setup options configuration. To do this, we use a custom function which runs the 
chosen model firstly on the first data "window" (which can be selected to be 
however many quarters desired) and then moves this window forward in time by one
quarter at a time, running the estimation for each loop. We then use another
custom function to plot the resulting coefficients through time, including 
confidence intervals.

```{r rolling TR, message=FALSE, warning=FALSE}

source(here("helpers/roll_TR_estimator.R"))

# Estimate a rolling-window (W in quarters) Taylor Rule specification
TR_roll <- estimate_rolling_TR(data, model_formula, W = 30)

# Plotting (note: this part is not modular, obviously)
plot_rolling_coefs(TR_roll, "rate_lag", var_name_title="Rate Lag")
plot_rolling_coefs(TR_roll, "inflation_gap", var_name_title="Inflation (Gap)")
plot_rolling_coefs(TR_roll, "output_gap", var_name_title="Output Gap")

```


```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```


# Forecasting Model Evaluation

## Methodology
Our method of forecasting consists of two steps. First, we run our custom auto 
ARIMA function on the inputs of the Taylor Rule (inflation and output gap). This 
function replicates the one in the "forecast" package, though does not loop over
the differentiation parameter as we want to set that value manually based on the 
stationarity tests run above. We additionally run this function on the interest
rate in order to serve as our benchmark model for relative forecasting performance 
evaluation. In order to compute the forecasts based on the fitted ARIMA models,
we use a custom function that replicates the same use-case in the "forecast" package.
At the same time as the ARIMA fits, we use OLS to compute the Taylor Rule coefficients.
The second step is then to do the actual forecasting, where we predict future values
of the interest rate based on the forecasted values of the inputs using the fitted
ARIMA models, weighted by the coefficients computed with OLS. 

```{r auto_arima_func, echo=TRUE, message=FALSE, warning=FALSE}

source(here("helpers/auto_ARIMA_replic.R"))

```


## Pseudo Out of Sample Estimation
In order to asses the performance of this methodology, we use a pseudo out-of-sample
rolling estimation scheme of direct forecasts for all Taylor Rule formulas and for
the benchmark ARIMA. We forecast up to a horizon of 10 quarters ahead. 
To do this, we loop over quarters starting just before the evaluation sample,
where we then implement our methodology to forecast up to the farthest horizon.
We then store these values and the loop starts again, adding one more quarter from
the evaluation sample, and dropping the very first quarter in the overall sample.
For the lagged models, we additionally need to include an iterative forecasting step, where 
we loop over each horizon in order to use the previous point forecast to compute
the next one. In order to speed up the process, we include a simple parallelization
procedure which runs these loops in parallel on a fourth the the users' CPU cores.

```{r pseudo-out-of-sample-parameters, echo=TRUE, message=FALSE, warning=FALSE}

#add explain parameters
R = 85 # Chow: Structural breaks at R=55 and R=85 
cat("Evaluation sample starts after ",as.character(data$quarter[R]),".",sep="")
P = nrow(data) - R #but will effectively be: P = T-h-R
H = 10 # Number of different horizons (takes 10 to go until 2027 Q4)

```

```{r pseudo-out-of-sample-estimation, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

source(here("scripts/pseudo_out_of_sample_estimation.R"))

```

## Spaghetti Plots
In order to visualize the pseudo out-of-sample evaluation exercise, we use spaghetti
plots of the point forecasts which allow to compare how often the model "misses" the 
realised values of the interest rate between different horizons and dates. We do
the plot only on the on the Taylor Rule formula selected in the options configuration
in order to avoid clutter.

```{r Spaghetti Plot, message=FALSE, warning=FALSE}

spaghetti_plotter(evals = eval_all_models,
                  model = model,
                  model_name = model_name)

```

## Forecast Errors 

### Plots of FE
Similar to the spaghetti plot of the point forecasts, we essentially use the same 
plot but computing the forecast errors as the difference between our point
forecast and the realised value.
```{r Plot of Forecast Errors, warning=FALSE, message=FALSE}

FE_spaghetti_plotter(evals = eval_all_models)

```

### Density of FE
We can then plot the distribution of these forecast errors using a density plot.
We include 3 versions: one that is unscaled in order to compare the absolute values,
one that is scaled in order to compare relative differences, and one that plots
density in a way to compare both.
```{r Density of Forecast Errors}

FE_density_plotter_unscaled(evals = eval_all_models)
FE_density_plotter_scaled(evals = eval_all_models)
FE_density_plotter_ridges(evals = eval_all_models)

```

### Variance of FE
```{r Variance of Forecast Errors}

FE_variance_plotter(var_by_horizon)

```

### Horizon 1 Autocorrelation of FE
\textcolor{red}{Model 1, 2, 3 are autocorrelated at h=1. Include results in paper,
not here in the appendix. Well maybe not idk.}
```{r Durbin Watson test, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

#Durbin Watson tests for first autocorrelation at h=1

# Select Forecast Columns
formula_cols <- grep("^F_TR_FORMULA_", names(eval_all_models), value = TRUE)

# Automatically set max horizon for loop
max_h <- max(eval_all_models$horizon)

# Loop for each model
for (e_model_name in formula_cols) {

  # Extract and regress errors
  all_forecast_errors <- eval_all_models[["actuals"]] - eval_all_models[[e_model_name]]
  h1_errors_vector <- all_forecast_errors[eval_all_models$horizon == 1]
  temp_model <- lm(h1_errors_vector ~ 1)

  # Durbin-Watson Test
  dw_test_result <- durbinWatsonTest(temp_model)

  # Print output
  cat(sprintf("\n--- Durbin-Watson Test for Model: %s (h=1) ---\n", e_model_name))
  print(dw_test_result)
  cat(sprintf("DW Statistic: %.4f\n", dw_test_result$statistic))}

```


### Overall Autocorrelation of FE
\textcolor{red}{We don't reject H0 -> h+1 are uncorrelated
1,2, are autocorrelated, 3 and 4 are not.}

```{r Ljung Box test, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

#Ljung Box Test, with Columns & max lags set in Durbin Watson code chunk

# Loop through each TR
for (e_model_name in formula_cols) {
    
    cat(sprintf("--- Checking Errors for Model: %s ---\n", e_model_name))
    
    # Calculate the errors of the model
    all_errors <- eval_all_models[["actuals"]] - eval_all_models[[e_model_name]]
    
    # Loop over all forecast horizons to test for autocorrelation
    for (h in 1:max_h){
        
        # select errors for each horizon
        h_errors <- all_errors[eval_all_models$horizon == h]
            
        # max lag according to slides around sqrt T
        T_errors <- length(h_errors)
        max_lag <- 4 #round(sqrt(T_errors)) # use 4 or 5 chose 4 because 1 year has 4 quarters
        
        # Ljung-Box Test
        lb_test_result <- Box.test(h_errors, 
                                   lag = max_lag, 
                                   type = "Ljung-Box")
        
        #Print Results
        cat(sprintf("Horizon h=%d (N=%d, Lags=%d): Q=%.2f, p-value=%.3f\n", 
                    h, T_errors, max_lag, lb_test_result$statistic, lb_test_result$p.value))}
        cat("\n")}

```

### Errors Normally Distributed
Run the Jarque Bera Test with helpers

```{r jb_test_func, echo=TRUE, message=TRUE, warning=FALSE}

# in final markdown, input just the relevant code, i.e. the tests made
# who cares about code to create tables, that stays in helpers
source(here("helpers/pseudo_outofsample_tests.R"))

```

```{r Jarque Bera Test, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Run with helper functions
# missing benchmark
generate_all_jb_reports(
  formula_cols =  formula_cols,
  eval_all_models = eval_all_models,
  max_h = max_h)

```




## Absolute Performance: Efficiency \& Bias
```{r mz_test_func, echo=TRUE, message=TRUE, warning=FALSE}

# in final markdown, input just the relevant code, i.e. the tests made
# who cares about code to create tables, that stays in helpers
source(here("helpers/pseudo_outofsample_tests.R"))

```


```{r forecast-model-efficiency, echo=TRUE, message=TRUE, warning=FALSE, results='asis'}

# Call MZ-test helper function 4 times.
#  Note: These reports is wrapped in trycatch as it sometimes fails
#         If it does fail, simply decrease R in order to have more 
#          observations, removing potential multicolinearity.

# MZ Report 1: Actual Rate, No Lag
mz_report_1 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_1,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Actual Rate, No Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Actual Rate, No Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 2: Shadow Rate, No Lag (
mz_report_2 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_2,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Shadow Rate, No Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Shadow Rate, No Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 3: Actual Rate, with Lag
mz_report_3 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_3,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Actual Rate, with Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Actual Rate, with Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 4: Shadow Rate, with Lag
mz_report_4 <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_TR_4,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Shadow Rate, with Lag",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Shadow Rate, with Lag): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

# MZ Report 5: Benchmark
mz_report_BM <- tryCatch({
  generate_absolute_performance_report(
    F_model = F_BM,
    Actual_values = Actuals,
    H = H,
    model_caption = "Mincer-Zarnowitz Test: Benchmark ARIMA",
    format = format)}, error = function(e) {
  message("Error generating MZ Report (Benchmark ARIMA): ", e$message)
  message("Skipping this report and continuing...")
  return(NULL)})

list(mz_report_1, mz_report_2, mz_report_3, mz_report_4, mz_report_BM)

```


## Relative Performance (against benchmark)
```{r dm_test_func, echo=TRUE, message=TRUE, warning=FALSE}

# in final markdown, input just the relevant code, i.e. the tests made
# who cares about code to create tables, that stays in helpers
source(here("helpers/pseudo_outofsample_tests.R"))

```

```{r forecast-model-perf, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

# Call DM-test helper function 4 times.

# Report 1: Actual Rate, No Lag
report_1 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_1,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, No Lag",
  format = format)

# Report 2: Shadow Rate, No Lag
report_2 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_2,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Shadow Rate, No Lag",
  format = format)

# Report 3: Actual Rate, with Lag
report_3 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_3,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Actual Rate, with Lag",
  format = format)

# Report 4: Shadow Rate, with Lag
report_4 <- generate_relative_performance_report(
  FE_TR_model = FE_TR_4,
  FE_BM_model = FE_BM,
  H = H,
  model_caption = "MSFE Comparison, Trained on Shadow Rate, with Lag",
  format = format)

list(report_1, report_2, report_3, report_4)

```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```



# Actual Forecast Model

## Forecasting
```{r forecast, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

source(here("helpers/actual_forecast_estimator.R"))

final_forecasts <- our_predict(data = data, formula = model_formula, H = H)
 
display_forecasts(final_forecasts, 
                  caption = paste("For model based on:", model_name),
                  format = format)

plot_forecasts(final_forecasts)
 
```

## Prediction Intervals

Prepare Data
```{r prediction_intervals, echo=TRUE, message=FALSE, warning=FALSE, results='asis'}

source(here("helpers/actual_forecast_estimator.R"))

# Computes prediction intervals
final_interval <- our_predict_intervals(estimated_variance = var_by_horizon,
                                        forecast = final_forecasts)

# Plots prediction intervals
plot_forecasts_pred_int(data, intervals = final_interval)

```















